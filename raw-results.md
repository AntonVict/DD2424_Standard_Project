## Stage 1 Binary Classification Run (2025-05-14_00-09-01)
![](logs/plots/stage1-binary-2025-05-14_00-09-01-loss.png)
![](logs/plots/stage1-binary-2025-05-14_00-09-01-acc.png)

**Log:**

[Telemetry] Number of training samples: 2944
[Telemetry] Number of validation samples: 736
[Telemetry] Number of test samples: 3669
[Telemetry] Batch size: 32
[Telemetry] Using device: mps

[Telemetry] Starting epoch 1/15
[Telemetry][Epoch 1] Batch 92/92 | Loss: 0.0759 | Acc: 0.9688
[Telemetry] Epoch 1 | Train Loss: 0.0855 | Train Acc: 0.9688
[Telemetry] Epoch 1 | Val Loss: 0.0377 | Val Acc: 0.9837

[Telemetry] Starting epoch 2/15
[Telemetry][Epoch 2] Batch 92/92 | Loss: 0.0046 | Acc: 1.0000
[Telemetry] Epoch 2 | Train Loss: 0.0193 | Train Acc: 0.9939
[Telemetry] Epoch 2 | Val Loss: 0.0540 | Val Acc: 0.9769

[Telemetry] Starting epoch 3/15
[Telemetry][Epoch 3] Batch 92/92 | Loss: 0.0034 | Acc: 1.0000
[Telemetry] Epoch 3 | Train Loss: 0.0124 | Train Acc: 0.9959
[Telemetry] Epoch 3 | Val Loss: 0.0227 | Val Acc: 0.9905

[Telemetry] Starting epoch 4/15
[Telemetry][Epoch 4] Batch 92/92 | Loss: 0.0009 | Acc: 1.0000
[Telemetry] Epoch 4 | Train Loss: 0.0046 | Train Acc: 0.9997
[Telemetry] Epoch 4 | Val Loss: 0.0253 | Val Acc: 0.9918

[Telemetry] Starting epoch 5/15
[Telemetry][Epoch 5] Batch 92/92 | Loss: 0.0119 | Acc: 1.0000
[Telemetry] Epoch 5 | Train Loss: 0.0106 | Train Acc: 0.9963
[Telemetry] Epoch 5 | Val Loss: 0.0222 | Val Acc: 0.9878

[Telemetry] Starting epoch 6/15
[Telemetry][Epoch 6] Batch 92/92 | Loss: 0.0009 | Acc: 1.0000
[Telemetry] Epoch 6 | Train Loss: 0.0147 | Train Acc: 0.9952
[Telemetry] Epoch 6 | Val Loss: 0.0201 | Val Acc: 0.9905

[Telemetry] Starting epoch 7/15
[Telemetry][Epoch 7] Batch 92/92 | Loss: 0.0003 | Acc: 1.0000
[Telemetry] Epoch 7 | Train Loss: 0.0086 | Train Acc: 0.9983
[Telemetry] Epoch 7 | Val Loss: 0.0244 | Val Acc: 0.9918

[Telemetry] Starting epoch 8/15
[Telemetry][Epoch 8] Batch 92/92 | Loss: 0.0003 | Acc: 1.0000
[Telemetry] Epoch 8 | Train Loss: 0.0063 | Train Acc: 0.9986
[Telemetry] Epoch 8 | Val Loss: 0.0102 | Val Acc: 0.9959

[Telemetry] Starting epoch 9/15
[Telemetry][Epoch 9] Batch 92/92 | Loss: 0.0011 | Acc: 1.0000
[Telemetry] Epoch 9 | Train Loss: 0.0030 | Train Acc: 0.9993
[Telemetry] Epoch 9 | Val Loss: 0.0135 | Val Acc: 0.9932

[Telemetry] Starting epoch 10/15
[Telemetry][Epoch 10] Batch 92/92 | Loss: 0.0013 | Acc: 1.0000
[Telemetry] Epoch 10 | Train Loss: 0.0038 | Train Acc: 0.9993
[Telemetry] Epoch 10 | Val Loss: 0.0410 | Val Acc: 0.9878

[Telemetry] Starting epoch 11/15
[Telemetry][Epoch 11] Batch 92/92 | Loss: 0.0016 | Acc: 1.0000
[Telemetry] Epoch 11 | Train Loss: 0.0054 | Train Acc: 0.9980
[Telemetry] Epoch 11 | Val Loss: 0.0180 | Val Acc: 0.9959

[Telemetry] Starting epoch 12/15
[Telemetry][Epoch 12] Batch 92/92 | Loss: 0.0002 | Acc: 1.0000
[Telemetry] Epoch 12 | Train Loss: 0.0018 | Train Acc: 0.9997
[Telemetry] Epoch 12 | Val Loss: 0.0304 | Val Acc: 0.9891

[Telemetry] Starting epoch 13/15
[Telemetry][Epoch 13] Batch 92/92 | Loss: 0.0002 | Acc: 1.0000
[Telemetry] Epoch 13 | Train Loss: 0.0009 | Train Acc: 1.0000
[Telemetry] Epoch 13 | Val Loss: 0.0327 | Val Acc: 0.9878

[Telemetry] Starting epoch 14/15
[Telemetry][Epoch 14] Batch 92/92 | Loss: 0.0004 | Acc: 1.0000
[Telemetry] Epoch 14 | Train Loss: 0.0004 | Train Acc: 1.0000
[Telemetry] Epoch 14 | Val Loss: 0.0162 | Val Acc: 0.9918

[Telemetry] Starting epoch 15/15
[Telemetry][Epoch 15] Batch 92/92 | Loss: 0.0001 | Acc: 1.0000
[Telemetry] Epoch 15 | Train Loss: 0.0004 | Train Acc: 1.0000
[Telemetry] Epoch 15 | Val Loss: 0.0201 | Val Acc: 0.9946
[Telemetry] Test Loss: 0.0368 | Test Acc: 0.9891


## Stage 1 Binary Classification Run (2025-05-15_14-15-45)
![](logs\plots\stage1-binary-2025-05-15_14-15-45-loss.png)
![](logs\plots\stage1-binary-2025-05-15_14-15-45-acc.png)

**Log:**

[Telemetry] Number of training samples: 2944
[Telemetry] Number of validation samples: 736
[Telemetry] Number of test samples: 3669
[Telemetry] Batch size: 32
[Telemetry] Using device: cpu

[Telemetry] Starting epoch 1/1
[Telemetry][Epoch 1] Batch 92/92 | Loss: 0.0101 | Acc: 1.0000
[Telemetry] Epoch 1 | Train Loss: 0.0830 | Train Acc: 0.9704
[Telemetry] Epoch 1 | Val Loss: 0.0631 | Val Acc: 0.9851
[Telemetry] Test Loss: 0.0490 | Test Acc: 0.9817


## Stage 1 Binary Classification Run (2025-05-15_14-41-31)
![](logs\plots\stage1-binary-2025-05-15_14-41-31-loss.png)
![](logs\plots\stage1-binary-2025-05-15_14-41-31-acc.png)

**Log:**

[Telemetry] Number of training samples: 2944
[Telemetry] Number of validation samples: 736
[Telemetry] Number of test samples: 3669
[Telemetry] Batch size: 32
[Telemetry] Using device: cpu

[Telemetry] Starting epoch 1/1
[Telemetry][Epoch 1] Batch 10/92 | Train Loss (last 10): 0.6122 | Train Acc (last 10): 0.6969
[Telemetry][Epoch 1] Batch 10/92 | Val Loss: 0.5956 | Val Acc: 0.6807
[Telemetry][Epoch 1] Batch 20/92 | Train Loss (last 10): 0.5854 | Train Acc (last 10): 0.6813
[Telemetry][Epoch 1] Batch 20/92 | Val Loss: 0.5680 | Val Acc: 0.7079
[Telemetry][Epoch 1] Batch 30/92 | Train Loss (last 10): 0.5507 | Train Acc (last 10): 0.7094
[Telemetry][Epoch 1] Batch 30/92 | Val Loss: 0.5481 | Val Acc: 0.7160
[Telemetry][Epoch 1] Batch 40/92 | Train Loss (last 10): 0.5414 | Train Acc (last 10): 0.7406
[Telemetry][Epoch 1] Batch 40/92 | Val Loss: 0.5357 | Val Acc: 0.7255
[Telemetry][Epoch 1] Batch 50/92 | Train Loss (last 10): 0.5137 | Train Acc (last 10): 0.7250
[Telemetry][Epoch 1] Batch 50/92 | Val Loss: 0.5191 | Val Acc: 0.7296
[Telemetry][Epoch 1] Batch 60/92 | Train Loss (last 10): 0.5110 | Train Acc (last 10): 0.7344
[Telemetry][Epoch 1] Batch 60/92 | Val Loss: 0.4979 | Val Acc: 0.7514
[Telemetry][Epoch 1] Batch 70/92 | Train Loss (last 10): 0.5153 | Train Acc (last 10): 0.7500
[Telemetry][Epoch 1] Batch 70/92 | Val Loss: 0.4836 | Val Acc: 0.7867
[Telemetry][Epoch 1] Batch 80/92 | Train Loss (last 10): 0.4980 | Train Acc (last 10): 0.7688
[Telemetry][Epoch 1] Batch 80/92 | Val Loss: 0.4747 | Val Acc: 0.8139
[Telemetry][Epoch 1] Batch 90/92 | Train Loss (last 10): 0.4842 | Train Acc (last 10): 0.8031
[Telemetry][Epoch 1] Batch 90/92 | Val Loss: 0.4606 | Val Acc: 0.8274
[Telemetry][Epoch 1] Batch 92/92 | Train Loss (last 10): 0.4062 | Train Acc (last 10): 0.9062
[Telemetry][Epoch 1] Batch 92/92 | Val Loss: 0.4573 | Val Acc: 0.8302
[Telemetry] Epoch 1 | Train Loss: 0.5319 | Train Acc: 0.7381
[Telemetry] Test Loss: 0.6325 | Test Acc: 0.6574


## Stage 1 Binary Classification Run (2025-05-15_14-56-16)
![](logs\plots\stage1-binary-2025-05-15_14-56-16-loss.png)
![](logs\plots\stage1-binary-2025-05-15_14-56-16-acc.png)

**Log:**

[Telemetry] Number of training samples: 2944
[Telemetry] Number of validation samples: 736
[Telemetry] Number of test samples: 3669
[Telemetry] Batch size: 32
[Telemetry] Using device: cpu

[Telemetry] Starting epoch 1/1
[Telemetry][Epoch 1] Batch 10/92 | Train Loss (last 10): 0.7019 | Train Acc (last 10): 0.5281
[Telemetry][Epoch 1] Batch 10/92 | Val Loss: 0.6787 | Val Acc: 0.5842
[Telemetry][Epoch 1] Batch 20/92 | Train Loss (last 10): 0.6557 | Train Acc (last 10): 0.6312
[Telemetry][Epoch 1] Batch 20/92 | Val Loss: 0.6431 | Val Acc: 0.6671
[Telemetry][Epoch 1] Batch 30/92 | Train Loss (last 10): 0.6328 | Train Acc (last 10): 0.6719
[Telemetry][Epoch 1] Batch 30/92 | Val Loss: 0.6198 | Val Acc: 0.6875
[Telemetry][Epoch 1] Batch 40/92 | Train Loss (last 10): 0.6068 | Train Acc (last 10): 0.7094
[Telemetry][Epoch 1] Batch 40/92 | Val Loss: 0.5972 | Val Acc: 0.7038
[Telemetry][Epoch 1] Batch 50/92 | Train Loss (last 10): 0.6258 | Train Acc (last 10): 0.6719
[Telemetry][Epoch 1] Batch 50/92 | Val Loss: 0.5815 | Val Acc: 0.7160
[Telemetry][Epoch 1] Batch 60/92 | Train Loss (last 10): 0.5510 | Train Acc (last 10): 0.7438
[Telemetry][Epoch 1] Batch 60/92 | Val Loss: 0.5607 | Val Acc: 0.7351
[Telemetry][Epoch 1] Batch 70/92 | Train Loss (last 10): 0.5297 | Train Acc (last 10): 0.7531
[Telemetry][Epoch 1] Batch 70/92 | Val Loss: 0.5416 | Val Acc: 0.7432
[Telemetry][Epoch 1] Batch 80/92 | Train Loss (last 10): 0.5509 | Train Acc (last 10): 0.7156
[Telemetry][Epoch 1] Batch 80/92 | Val Loss: 0.5276 | Val Acc: 0.7514
[Telemetry][Epoch 1] Batch 90/92 | Train Loss (last 10): 0.5102 | Train Acc (last 10): 0.7531
[Telemetry][Epoch 1] Batch 90/92 | Val Loss: 0.5098 | Val Acc: 0.7704
[Telemetry][Epoch 1] Batch 92/92 | Train Loss (last 10): 0.5098 | Train Acc (last 10): 0.7656
[Telemetry][Epoch 1] Batch 92/92 | Val Loss: 0.5077 | Val Acc: 0.7812
[Telemetry] Epoch 1 | Train Loss: 0.5942 | Train Acc: 0.6882
[Telemetry] Test Loss: 0.6343 | Test Acc: 0.6778


## Stage 1 Binary Classification Run (2025-05-15_15-53-39)
![](logs\plots\stage1-binary-2025-05-15_15-53-39-loss.png)
![](logs\plots\stage1-binary-2025-05-15_15-53-39-acc.png)

**Log:**

[Telemetry] Number of training samples: 3312
[Telemetry] Number of validation samples: 368
[Telemetry] Number of test samples: 3669
[Telemetry] Batch size: 32
[Telemetry] Using device: cpu

[Telemetry] Starting epoch 1/3
[Telemetry][Epoch 1] Batch 20/104 | Train Loss (last 10): 0.1786 | Train Acc (last 10): 0.9219
[Telemetry][Epoch 1] Batch 20/104 | Val Loss: 0.0465 | Val Acc: 0.9783
[Telemetry][Epoch 1] Batch 40/104 | Train Loss (last 10): 0.0479 | Train Acc (last 10): 0.9797
[Telemetry][Epoch 1] Batch 40/104 | Val Loss: 0.0273 | Val Acc: 0.9918
[Telemetry][Epoch 1] Batch 60/104 | Train Loss (last 10): 0.0338 | Train Acc (last 10): 0.9844
[Telemetry][Epoch 1] Batch 60/104 | Val Loss: 0.0490 | Val Acc: 0.9837
[Telemetry][Epoch 1] Batch 80/104 | Train Loss (last 10): 0.0689 | Train Acc (last 10): 0.9750
[Telemetry][Epoch 1] Batch 80/104 | Val Loss: 0.0420 | Val Acc: 0.9810
[Telemetry][Epoch 1] Batch 100/104 | Train Loss (last 10): 0.0461 | Train Acc (last 10): 0.9859
[Telemetry][Epoch 1] Batch 100/104 | Val Loss: 0.0170 | Val Acc: 0.9946
[Telemetry][Epoch 1] Batch 104/104 | Train Loss (last 10): 0.0383 | Train Acc (last 10): 0.9821
[Telemetry][Epoch 1] Batch 104/104 | Val Loss: 0.0364 | Val Acc: 0.9864
[Telemetry] Epoch 1 | Train Loss: 0.0738 | Train Acc: 0.9698

[Telemetry] Starting epoch 2/3
[Telemetry][Epoch 2] Batch 20/104 | Train Loss (last 10): 0.0195 | Train Acc (last 10): 0.9969
[Telemetry][Epoch 2] Batch 20/104 | Val Loss: 0.0161 | Val Acc: 0.9946
[Telemetry][Epoch 2] Batch 40/104 | Train Loss (last 10): 0.0120 | Train Acc (last 10): 0.9984
[Telemetry][Epoch 2] Batch 40/104 | Val Loss: 0.0138 | Val Acc: 0.9973
[Telemetry][Epoch 2] Batch 60/104 | Train Loss (last 10): 0.0137 | Train Acc (last 10): 0.9953
[Telemetry][Epoch 2] Batch 60/104 | Val Loss: 0.0070 | Val Acc: 0.9973
[Telemetry][Epoch 2] Batch 80/104 | Train Loss (last 10): 0.0124 | Train Acc (last 10): 0.9953
[Telemetry][Epoch 2] Batch 80/104 | Val Loss: 0.0131 | Val Acc: 0.9973
[Telemetry][Epoch 2] Batch 100/104 | Train Loss (last 10): 0.0222 | Train Acc (last 10): 0.9938
[Telemetry][Epoch 2] Batch 100/104 | Val Loss: 0.0119 | Val Acc: 0.9973
[Telemetry][Epoch 2] Batch 104/104 | Train Loss (last 10): 0.0523 | Train Acc (last 10): 0.9821
[Telemetry][Epoch 2] Batch 104/104 | Val Loss: 0.0207 | Val Acc: 0.9918
[Telemetry] Epoch 2 | Train Loss: 0.0172 | Train Acc: 0.9955

[Telemetry] Starting epoch 3/3
[Telemetry][Epoch 3] Batch 20/104 | Train Loss (last 10): 0.0167 | Train Acc (last 10): 0.9953
[Telemetry][Epoch 3] Batch 20/104 | Val Loss: 0.0169 | Val Acc: 0.9946
[Telemetry][Epoch 3] Batch 40/104 | Train Loss (last 10): 0.0071 | Train Acc (last 10): 0.9984
[Telemetry][Epoch 3] Batch 40/104 | Val Loss: 0.0151 | Val Acc: 0.9946
[Telemetry][Epoch 3] Batch 60/104 | Train Loss (last 10): 0.0068 | Train Acc (last 10): 0.9984
[Telemetry][Epoch 3] Batch 60/104 | Val Loss: 0.0165 | Val Acc: 0.9946
[Telemetry][Epoch 3] Batch 80/104 | Train Loss (last 10): 0.0072 | Train Acc (last 10): 0.9969
[Telemetry][Epoch 3] Batch 80/104 | Val Loss: 0.0243 | Val Acc: 0.9946
[Telemetry][Epoch 3] Batch 100/104 | Train Loss (last 10): 0.0198 | Train Acc (last 10): 0.9891
[Telemetry][Epoch 3] Batch 100/104 | Val Loss: 0.0254 | Val Acc: 0.9946
[Telemetry][Epoch 3] Batch 104/104 | Train Loss (last 10): 0.0121 | Train Acc (last 10): 1.0000
[Telemetry][Epoch 3] Batch 104/104 | Val Loss: 0.0235 | Val Acc: 0.9946
[Telemetry] Epoch 3 | Train Loss: 0.0115 | Train Acc: 0.9958
[Telemetry] Test Loss: 2.0225 | Test Acc: 0.6956


## Stage 2 Multi-class Classification Run (2025-05-15_17-04-19)
![](logs\plots\stage2-multiclass-2025-05-15_17-04-19-loss.png)
![](logs\plots\stage2-multiclass-2025-05-15_17-04-19-acc.png)

**Log:**

[Telemetry] Number of training samples: 2944
[Telemetry] Number of validation samples: 736
[Telemetry] Batch size: 32
[Telemetry] Using device: cpu
[Telemetry] Strategy: simultaneous
[Telemetry] Fine-tuning last 2 layers + classifier from start.

[Telemetry] Starting epoch 1/1
[Telemetry][Epoch 1] Batch 92/92 | Loss: 3.0719 | Acc: 0.1562
[Telemetry] Epoch 1 | Train Loss: 3.4323 | Train Acc: 0.1162
[Telemetry] Epoch 1 | Val Loss: 3.0489 | Val Acc: 0.2514


## Stage 2 Multi-class Classification Run (2025-05-15_17-16-11)
![](logs\plots\stage2-multiclass-2025-05-15_17-16-11-loss.png)
![](logs\plots\stage2-multiclass-2025-05-15_17-16-11-acc.png)
![](logs\plots\stage2-multiclass-2025-05-15_17-16-11-val-loss.png)
![](logs\plots\stage2-multiclass-2025-05-15_17-16-11-val-acc.png)

**Log:**

[Telemetry] Number of training samples: 3496
[Telemetry] Number of validation samples: 184
[Telemetry] Batch size: 32
[Telemetry] Using device: cpu
[Telemetry] Strategy: simultaneous
[Telemetry] Fine-tuning last 1 layers + classifier from start.

[Telemetry] Starting epoch 1/1
[Telemetry][Epoch 1][Iter 1] Val Loss: 3.8510 | Val Acc: 0.0435
[Telemetry][Epoch 1][Iter 11] Val Loss: 3.7118 | Val Acc: 0.0380
[Telemetry][Epoch 1][Iter 21] Val Loss: 3.6121 | Val Acc: 0.0489
[Telemetry][Epoch 1][Iter 31] Val Loss: 3.5289 | Val Acc: 0.0489
[Telemetry][Epoch 1][Iter 41] Val Loss: 3.4509 | Val Acc: 0.0870
[Telemetry][Epoch 1][Iter 51] Val Loss: 3.3686 | Val Acc: 0.1196
[Telemetry][Epoch 1][Iter 61] Val Loss: 3.3005 | Val Acc: 0.1576
[Telemetry][Epoch 1][Iter 71] Val Loss: 3.2338 | Val Acc: 0.1739
[Telemetry][Epoch 1][Iter 81] Val Loss: 3.1640 | Val Acc: 0.1902
[Telemetry][Epoch 1][Iter 91] Val Loss: 3.0969 | Val Acc: 0.2174
[Telemetry][Epoch 1] Batch 100/110 | Loss: 3.0649 | Acc: 0.3750
[Telemetry][Epoch 1][Iter 101] Val Loss: 3.0357 | Val Acc: 0.2174
[Telemetry][Epoch 1] Batch 110/110 | Loss: 3.3830 | Acc: 0.1250
[Telemetry] Epoch 1 | Train Loss: 3.3893 | Train Acc: 0.1107


## Stage 2 Multi-class Classification Run (2025-05-15_17-25-04)
![](logs\plots\stage2-multiclass-2025-05-15_17-25-04-loss.png)
![](logs\plots\stage2-multiclass-2025-05-15_17-25-04-acc.png)
![](logs\plots\stage2-multiclass-2025-05-15_17-25-04-val-loss.png)
![](logs\plots\stage2-multiclass-2025-05-15_17-25-04-val-acc.png)

**Log:**

[Telemetry] Number of training samples: 349
[Telemetry] Number of validation samples: 184
[Telemetry] Batch size: 32
[Telemetry] Using device: cpu
[Telemetry] Strategy: simultaneous
[Telemetry] Fine-tuning last 1 layers + classifier from start.

[Telemetry] Starting epoch 1/1
[Telemetry][Epoch 1][Iter 1] Val Loss: 3.8089 | Val Acc: 0.0163
[Telemetry][Epoch 1] Batch 11/11 | Loss: 3.7382 | Acc: 0.0000
[Telemetry][Epoch 1][Iter 11] Val Loss: 3.7129 | Val Acc: 0.0217
[Telemetry] Epoch 1 | Train Loss: 3.8350 | Train Acc: 0.0258


## Stage 2 Multi-class Classification Run (2025-05-15_17-43-56)


## Stage 2 Multi-class Classification Run (2025-05-15_17-45-38)
![](logs\plots\stage2-multiclass-2025-05-15_17-45-38-val-loss.png)
![](logs\plots\stage2-multiclass-2025-05-15_17-45-38-val-acc.png)
![](logs\plots\stage2-multiclass-2025-05-15_17-45-38-combined-iter.png)

**Log:**

[Telemetry] Number of training samples: 349
[Telemetry] Number of validation samples: 184
[Telemetry] Batch size: 32
[Telemetry] Using device: cpu
[Telemetry] Strategy: simultaneous
[Telemetry] Fine-tuning last 1 layers + classifier from start.

[Telemetry] Starting epoch 1/1
[Telemetry][Epoch 1][Iter 1] Val Loss: 3.8609 | Val Acc: 0.0217
[Telemetry][Epoch 1] Batch 11/11 | Loss: 4.0142 | Acc: 0.0345
[Telemetry][Epoch 1][Iter 11] Val Loss: 3.7844 | Val Acc: 0.0272
[Telemetry] Epoch 1 | Train Loss: 3.8438 | Train Acc: 0.0287


## Stage 2 Multi-class Classification Run (2025-05-15_17-53-47)
![](logs\plots\stage2-multiclass-2025-05-15_17-53-47-combined-iter.png)
![](logs\plots\stage2-multiclass-2025-05-15_17-53-47-combined-iter.png)

**Log:**

[Telemetry] Number of training samples: 349
[Telemetry] Number of validation samples: 184
[Telemetry] Batch size: 32
[Telemetry] Using device: cpu
[Telemetry] Strategy: simultaneous
[Telemetry] Fine-tuning last 1 layers + classifier from start.

[Telemetry] Starting epoch 1/1
[Telemetry][Epoch 1][Iter 1] Val Loss: 3.8172 | Val Acc: 0.0217
[Telemetry][Epoch 1] Batch 11/11 | Loss: 3.6047 | Acc: 0.0345
[Telemetry][Epoch 1][Iter 11] Val Loss: 3.6791 | Val Acc: 0.0489
[Telemetry] Epoch 1 | Train Loss: 3.7301 | Train Acc: 0.0487


## Stage 2 Multi-class Classification Run (2025-05-15_17-55-33)
![](logs\plots\stage2-multiclass-2025-05-15_17-55-33-combined-iter.png)
![](logs\plots\stage2-multiclass-2025-05-15_17-55-33-combined-iter.png)

**Log:**

[Telemetry] Number of training samples: 349
[Telemetry] Number of validation samples: 184
[Telemetry] Batch size: 32
[Telemetry] Using device: cpu
[Telemetry] Strategy: simultaneous
[Telemetry] Fine-tuning last 1 layers + classifier from start.

[Telemetry] Starting epoch 1/1
[Telemetry][Epoch 1][Iter 1] Val Loss: 3.7796 | Val Acc: 0.0000
[Telemetry][Epoch 1] Batch 11/11 | Loss: 3.6484 | Acc: 0.0000
[Telemetry][Epoch 1][Iter 11] Val Loss: 3.6803 | Val Acc: 0.0380
[Telemetry] Epoch 1 | Train Loss: 3.8131 | Train Acc: 0.0115


## Stage 2 Multi-class Classification Run (2025-05-15_17-57-23)
![](logs\plots\stage2-multiclass-2025-05-15_17-57-23-combined-iter.png)
![](logs\plots\stage2-multiclass-2025-05-15_17-57-23-combined-iter.png)

**Log:**

[Telemetry] Number of training samples: 3496
[Telemetry] Number of validation samples: 184
[Telemetry] Batch size: 32
[Telemetry] Using device: cpu
[Telemetry] Strategy: simultaneous
[Telemetry] Fine-tuning last 1 layers + classifier from start.

[Telemetry] Starting epoch 1/1
[Telemetry][Epoch 1][Iter 1] Val Loss: 3.8683 | Val Acc: 0.0217
[Telemetry][Epoch 1][Iter 11] Val Loss: 3.7232 | Val Acc: 0.0435
[Telemetry][Epoch 1][Iter 21] Val Loss: 3.6355 | Val Acc: 0.0543
[Telemetry][Epoch 1][Iter 31] Val Loss: 3.5489 | Val Acc: 0.0870
[Telemetry][Epoch 1][Iter 41] Val Loss: 3.4730 | Val Acc: 0.1087
[Telemetry][Epoch 1][Iter 51] Val Loss: 3.3995 | Val Acc: 0.1304
[Telemetry][Epoch 1][Iter 61] Val Loss: 3.3281 | Val Acc: 0.1522
[Telemetry][Epoch 1][Iter 71] Val Loss: 3.2677 | Val Acc: 0.1576
[Telemetry][Epoch 1][Iter 81] Val Loss: 3.2067 | Val Acc: 0.2011
[Telemetry][Epoch 1][Iter 91] Val Loss: 3.1377 | Val Acc: 0.2174
[Telemetry][Epoch 1] Batch 100/110 | Loss: 3.0681 | Acc: 0.2188
[Telemetry][Epoch 1][Iter 101] Val Loss: 3.0784 | Val Acc: 0.2337
[Telemetry][Epoch 1] Batch 110/110 | Loss: 3.1604 | Acc: 0.1250
[Telemetry] Epoch 1 | Train Loss: 3.3703 | Train Acc: 0.1196


## Stage 2 Multi-class Classification L Comparison Run (2025-05-15_18-07-45)
![](./logs\plots\stage2-multiclass-2025-05-15_18-07-45-l-comparison.png)

**Log:**

[Telemetry] Number of training samples: 349
[Telemetry] Batch size: 32
[Telemetry] Using device: cpu
[Telemetry] Strategy: simultaneous

[Telemetry] Training with L=1 (unfreezing last 1 layers + classifier)
Unfreezing layer4

[Telemetry] L=1, Starting epoch 1/1
[Telemetry][L=1][Epoch 1][Iter 1] Train Loss: 3.8580
[Telemetry][L=1][Epoch 1][Iter 11] Train Loss: 2.6010
[Telemetry][L=1][Epoch 1] Batch 11/11 | Loss: 2.6010 | Acc: 0.3793
[Telemetry][L=1] Epoch 1 | Train Loss: 3.2718 | Train Acc: 0.1490

[Telemetry] Training with L=2 (unfreezing last 2 layers + classifier)
Unfreezing layer4
Unfreezing layer3

[Telemetry] L=2, Starting epoch 1/1
[Telemetry][L=2][Epoch 1][Iter 1] Train Loss: 3.7711
[Telemetry][L=2][Epoch 1][Iter 11] Train Loss: 2.6994
[Telemetry][L=2][Epoch 1] Batch 11/11 | Loss: 2.6994 | Acc: 0.2759
[Telemetry][L=2] Epoch 1 | Train Loss: 3.2417 | Train Acc: 0.1433

[Telemetry] Training with L=3 (unfreezing last 3 layers + classifier)
Unfreezing layer4
Unfreezing layer3
Unfreezing layer2

[Telemetry] L=3, Starting epoch 1/1
[Telemetry][L=3][Epoch 1][Iter 1] Train Loss: 3.5138
[Telemetry][L=3][Epoch 1][Iter 11] Train Loss: 2.4888
[Telemetry][L=3][Epoch 1] Batch 11/11 | Loss: 2.4888 | Acc: 0.5172
[Telemetry][L=3] Epoch 1 | Train Loss: 3.1310 | Train Acc: 0.2206

[Telemetry] Training with L=4 (unfreezing last 4 layers + classifier)
Unfreezing layer4
Unfreezing layer3
Unfreezing layer2
Unfreezing layer1

[Telemetry] L=4, Starting epoch 1/1
[Telemetry][L=4][Epoch 1][Iter 1] Train Loss: 3.7097
[Telemetry][L=4][Epoch 1][Iter 11] Train Loss: 2.6150
[Telemetry][L=4][Epoch 1] Batch 11/11 | Loss: 2.6150 | Acc: 0.4138
[Telemetry][L=4] Epoch 1 | Train Loss: 3.2349 | Train Acc: 0.1777

[Telemetry] Training with L=5 (unfreezing last 5 layers + classifier)
Unfreezing layer4
Unfreezing layer3
Unfreezing layer2
Unfreezing layer1

[Telemetry] L=5, Starting epoch 1/1
[Telemetry][L=5][Epoch 1][Iter 1] Train Loss: 3.7608
[Telemetry][L=5][Epoch 1][Iter 11] Train Loss: 2.5976
[Telemetry][L=5][Epoch 1] Batch 11/11 | Loss: 2.5976 | Acc: 0.5517
[Telemetry][L=5] Epoch 1 | Train Loss: 3.1375 | Train Acc: 0.2407


## Stage 2 Multi-class Classification L Comparison Run (2025-05-15_18-14-37)
### Training Loss
![](./logs\plots\stage2-multiclass-2025-05-15_18-14-37-l-comparison-loss.png)

### Training Accuracy
![](./logs\plots\stage2-multiclass-2025-05-15_18-14-37-l-comparison-acc.png)


**Log:**

[Telemetry][L=1][Epoch 1] Batch 6/6 | Loss: 3.4583 | Acc: 0.1429
[Telemetry][L=1] Epoch 1 | Train Loss: 3.6337 | Train Acc: 0.0345

[Telemetry] Training with L=2 (unfreezing last 2 layers + classifier)
Unfreezing layer4
Unfreezing layer3

[Telemetry] L=2, Starting epoch 1/1
[Telemetry][L=2][Epoch 1][Iter 1] Train Loss: 3.7820 | Train Acc: 0.0312
[Telemetry][L=2][Epoch 1] Batch 6/6 | Loss: 3.6846 | Acc: 0.0714
[Telemetry][L=2] Epoch 1 | Train Loss: 3.6362 | Train Acc: 0.0747

[Telemetry] Training with L=3 (unfreezing last 3 layers + classifier)
Unfreezing layer4
Unfreezing layer3
Unfreezing layer2

[Telemetry] L=3, Starting epoch 1/1
[Telemetry][L=3][Epoch 1][Iter 1] Train Loss: 4.0007 | Train Acc: 0.0000
[Telemetry][L=3][Epoch 1] Batch 6/6 | Loss: 3.8987 | Acc: 0.0714
[Telemetry][L=3] Epoch 1 | Train Loss: 3.6187 | Train Acc: 0.0805


## Stage 2 Multi-class Classification L Comparison Run (2025-05-15_18-17-47)
### Training Loss
![](./logs\plots\stage2-multiclass-2025-05-15_18-17-47-l-comparison-loss.png)

### Training Accuracy
![](./logs\plots\stage2-multiclass-2025-05-15_18-17-47-l-comparison-acc.png)


**Log:**

[Telemetry] Number of training samples: 699
[Telemetry] Batch size: 32
[Telemetry] Using device: cpu
[Telemetry] Strategy: simultaneous

[Telemetry] Training with L=1 (unfreezing last 1 layers + classifier)
Unfreezing layer4

[Telemetry] L=1, Starting epoch 1/1
[Telemetry][L=1][Epoch 1][Iter 1] Train Loss: 3.8093 | Train Acc: 0.0000
[Telemetry][L=1][Epoch 1][Iter 6] Train Loss: 3.3149 | Train Acc: 0.1250
[Telemetry][L=1][Epoch 1][Iter 11] Train Loss: 2.5912 | Train Acc: 0.4688
[Telemetry][L=1][Epoch 1][Iter 16] Train Loss: 2.3240 | Train Acc: 0.4375
[Telemetry][L=1][Epoch 1][Iter 21] Train Loss: 1.9496 | Train Acc: 0.5938
[Telemetry][L=1][Epoch 1] Batch 22/22 | Loss: 1.7882 | Acc: 0.7037
[Telemetry][L=1] Epoch 1 | Train Loss: 2.7983 | Train Acc: 0.3319

[Telemetry] Training with L=2 (unfreezing last 2 layers + classifier)
Unfreezing layer4
Unfreezing layer3

[Telemetry] L=2, Starting epoch 1/1
[Telemetry][L=2][Epoch 1][Iter 1] Train Loss: 3.7017 | Train Acc: 0.0938
[Telemetry][L=2][Epoch 1][Iter 6] Train Loss: 3.2006 | Train Acc: 0.1875
[Telemetry][L=2][Epoch 1][Iter 11] Train Loss: 2.5127 | Train Acc: 0.4062
[Telemetry][L=2][Epoch 1][Iter 16] Train Loss: 2.1401 | Train Acc: 0.5938
[Telemetry][L=2][Epoch 1][Iter 21] Train Loss: 1.6542 | Train Acc: 0.7500
[Telemetry][L=2][Epoch 1] Batch 22/22 | Loss: 1.7983 | Acc: 0.5556
[Telemetry][L=2] Epoch 1 | Train Loss: 2.6630 | Train Acc: 0.3619

[Telemetry] Training with L=3 (unfreezing last 3 layers + classifier)
Unfreezing layer4
Unfreezing layer3
Unfreezing layer2

[Telemetry] L=3, Starting epoch 1/1
[Telemetry][L=3][Epoch 1][Iter 1] Train Loss: 3.7544 | Train Acc: 0.0312
[Telemetry][L=3][Epoch 1][Iter 6] Train Loss: 3.4312 | Train Acc: 0.0625
[Telemetry][L=3][Epoch 1][Iter 11] Train Loss: 2.5935 | Train Acc: 0.4062
[Telemetry][L=3][Epoch 1][Iter 16] Train Loss: 1.9926 | Train Acc: 0.6875
[Telemetry][L=3][Epoch 1][Iter 21] Train Loss: 1.7669 | Train Acc: 0.6875
[Telemetry][L=3][Epoch 1] Batch 22/22 | Loss: 1.8586 | Acc: 0.6296
[Telemetry][L=3] Epoch 1 | Train Loss: 2.6724 | Train Acc: 0.3906


## Stage 2 Multi-class Classification L Comparison Run (2025-05-15_18-25-16)
### Training Loss
![](./logs\plots\stage2-multiclass-2025-05-15_18-25-16-l-comparison-loss.png)

### Training Accuracy
![](./logs\plots\stage2-multiclass-2025-05-15_18-25-16-l-comparison-acc.png)


**Log:**

[Telemetry] Number of training samples: 3496
[Telemetry] Batch size: 32
[Telemetry] Using device: cpu
[Telemetry] Strategy: simultaneous

[Telemetry] Training with L=3 (unfreezing last 3 layers + classifier)
Unfreezing layer4
Unfreezing layer3
Unfreezing layer2

[Telemetry] L=3, Starting epoch 1/1
[Telemetry][L=3][Epoch 1][Iter 1] Train Loss: 3.6752 | Train Acc: 0.0312
[Telemetry][L=3][Epoch 1][Iter 6] Train Loss: 3.3175 | Train Acc: 0.0938
[Telemetry][L=3][Epoch 1][Iter 11] Train Loss: 2.7089 | Train Acc: 0.3750
[Telemetry][L=3][Epoch 1][Iter 16] Train Loss: 2.1559 | Train Acc: 0.4375
[Telemetry][L=3][Epoch 1][Iter 21] Train Loss: 1.8445 | Train Acc: 0.7812
[Telemetry][L=3][Epoch 1][Iter 26] Train Loss: 1.5731 | Train Acc: 0.7812
[Telemetry][L=3][Epoch 1][Iter 31] Train Loss: 1.3576 | Train Acc: 0.8125
[Telemetry][L=3][Epoch 1][Iter 36] Train Loss: 1.2796 | Train Acc: 0.7500
[Telemetry][L=3][Epoch 1][Iter 41] Train Loss: 1.1285 | Train Acc: 0.7188
[Telemetry][L=3][Epoch 1][Iter 46] Train Loss: 1.2390 | Train Acc: 0.7188
[Telemetry][L=3][Epoch 1][Iter 51] Train Loss: 0.8053 | Train Acc: 0.8438
[Telemetry][L=3][Epoch 1][Iter 56] Train Loss: 0.8652 | Train Acc: 0.9688
[Telemetry][L=3][Epoch 1][Iter 61] Train Loss: 0.8845 | Train Acc: 0.8125
[Telemetry][L=3][Epoch 1][Iter 66] Train Loss: 0.4980 | Train Acc: 0.8750
[Telemetry][L=3][Epoch 1][Iter 71] Train Loss: 0.5717 | Train Acc: 0.8438
[Telemetry][L=3][Epoch 1][Iter 76] Train Loss: 0.5427 | Train Acc: 1.0000
[Telemetry][L=3][Epoch 1][Iter 81] Train Loss: 0.3333 | Train Acc: 0.9688
[Telemetry][L=3][Epoch 1][Iter 86] Train Loss: 0.4685 | Train Acc: 0.9062
[Telemetry][L=3][Epoch 1][Iter 91] Train Loss: 0.4426 | Train Acc: 0.8750
[Telemetry][L=3][Epoch 1][Iter 96] Train Loss: 0.5829 | Train Acc: 0.9062
[Telemetry][L=3][Epoch 1] Batch 100/110 | Loss: 0.5141 | Acc: 0.8438
[Telemetry][L=3][Epoch 1][Iter 101] Train Loss: 0.3932 | Train Acc: 0.9688
[Telemetry][L=3][Epoch 1][Iter 106] Train Loss: 0.5426 | Train Acc: 0.9062
[Telemetry][L=3][Epoch 1] Batch 110/110 | Loss: 0.6349 | Acc: 0.7500
[Telemetry][L=3] Epoch 1 | Train Loss: 1.1602 | Train Acc: 0.7466

[Telemetry] Training with L=4 (unfreezing last 4 layers + classifier)
Unfreezing layer4
Unfreezing layer3
Unfreezing layer2
Unfreezing layer1

[Telemetry] L=4, Starting epoch 1/1
[Telemetry][L=4][Epoch 1][Iter 1] Train Loss: 3.8101 | Train Acc: 0.0625
[Telemetry][L=4][Epoch 1][Iter 6] Train Loss: 3.1272 | Train Acc: 0.2188
[Telemetry][L=4][Epoch 1][Iter 11] Train Loss: 2.8846 | Train Acc: 0.1875
[Telemetry][L=4][Epoch 1][Iter 16] Train Loss: 2.0448 | Train Acc: 0.6875
[Telemetry][L=4][Epoch 1][Iter 21] Train Loss: 1.4911 | Train Acc: 0.7812
[Telemetry][L=4][Epoch 1][Iter 26] Train Loss: 1.8745 | Train Acc: 0.5312
[Telemetry][L=4][Epoch 1][Iter 31] Train Loss: 1.4339 | Train Acc: 0.6250
[Telemetry][L=4][Epoch 1][Iter 36] Train Loss: 1.3818 | Train Acc: 0.6562
[Telemetry][L=4][Epoch 1][Iter 41] Train Loss: 1.0653 | Train Acc: 0.8438
[Telemetry][L=4][Epoch 1][Iter 46] Train Loss: 1.0859 | Train Acc: 0.8125
[Telemetry][L=4][Epoch 1][Iter 51] Train Loss: 0.8749 | Train Acc: 0.8438
[Telemetry][L=4][Epoch 1][Iter 56] Train Loss: 0.4515 | Train Acc: 1.0000
[Telemetry][L=4][Epoch 1][Iter 61] Train Loss: 0.7112 | Train Acc: 0.8750
[Telemetry][L=4][Epoch 1][Iter 66] Train Loss: 0.8642 | Train Acc: 0.7812
[Telemetry][L=4][Epoch 1][Iter 71] Train Loss: 0.7865 | Train Acc: 0.8125
[Telemetry][L=4][Epoch 1][Iter 76] Train Loss: 0.6172 | Train Acc: 0.8750
[Telemetry][L=4][Epoch 1][Iter 81] Train Loss: 0.6605 | Train Acc: 0.8438
[Telemetry][L=4][Epoch 1][Iter 86] Train Loss: 0.5435 | Train Acc: 0.8125
[Telemetry][L=4][Epoch 1][Iter 91] Train Loss: 0.6190 | Train Acc: 0.9062
[Telemetry][L=4][Epoch 1][Iter 96] Train Loss: 0.9111 | Train Acc: 0.7188
[Telemetry][L=4][Epoch 1] Batch 100/110 | Loss: 0.4849 | Acc: 0.9062
[Telemetry][L=4][Epoch 1][Iter 101] Train Loss: 0.4301 | Train Acc: 0.9375
[Telemetry][L=4][Epoch 1][Iter 106] Train Loss: 0.5449 | Train Acc: 0.8438
[Telemetry][L=4][Epoch 1] Batch 110/110 | Loss: 0.3970 | Acc: 1.0000
[Telemetry][L=4] Epoch 1 | Train Loss: 1.2216 | Train Acc: 0.7328

[Telemetry] Training with L=5 (unfreezing last 5 layers + classifier)
Unfreezing layer4
Unfreezing layer3
Unfreezing layer2
Unfreezing layer1

[Telemetry] L=5, Starting epoch 1/1
[Telemetry][L=5][Epoch 1][Iter 1] Train Loss: 4.0072 | Train Acc: 0.0312
[Telemetry][L=5][Epoch 1][Iter 6] Train Loss: 3.3647 | Train Acc: 0.0938
[Telemetry][L=5][Epoch 1][Iter 11] Train Loss: 3.1376 | Train Acc: 0.1562
[Telemetry][L=5][Epoch 1][Iter 16] Train Loss: 2.2283 | Train Acc: 0.4688
[Telemetry][L=5][Epoch 1][Iter 21] Train Loss: 1.8135 | Train Acc: 0.6875
[Telemetry][L=5][Epoch 1][Iter 26] Train Loss: 1.8668 | Train Acc: 0.5625
[Telemetry][L=5][Epoch 1][Iter 31] Train Loss: 1.6006 | Train Acc: 0.6875
[Telemetry][L=5][Epoch 1][Iter 36] Train Loss: 1.2611 | Train Acc: 0.7188
[Telemetry][L=5][Epoch 1][Iter 41] Train Loss: 1.1315 | Train Acc: 0.8125
[Telemetry][L=5][Epoch 1][Iter 46] Train Loss: 0.8670 | Train Acc: 0.8438
[Telemetry][L=5][Epoch 1][Iter 51] Train Loss: 0.9751 | Train Acc: 0.8125
[Telemetry][L=5][Epoch 1][Iter 56] Train Loss: 0.7973 | Train Acc: 0.8750
[Telemetry][L=5][Epoch 1][Iter 61] Train Loss: 0.6353 | Train Acc: 0.9688
[Telemetry][L=5][Epoch 1][Iter 66] Train Loss: 0.9269 | Train Acc: 0.8125
[Telemetry][L=5][Epoch 1][Iter 71] Train Loss: 1.0918 | Train Acc: 0.7188
[Telemetry][L=5][Epoch 1][Iter 76] Train Loss: 0.6969 | Train Acc: 0.8750
[Telemetry][L=5][Epoch 1][Iter 81] Train Loss: 0.6423 | Train Acc: 0.8125
[Telemetry][L=5][Epoch 1][Iter 86] Train Loss: 0.5387 | Train Acc: 0.9062
[Telemetry][L=5][Epoch 1][Iter 91] Train Loss: 0.4367 | Train Acc: 0.9375
[Telemetry][L=5][Epoch 1][Iter 96] Train Loss: 0.6825 | Train Acc: 0.8438
[Telemetry][L=5][Epoch 1] Batch 100/110 | Loss: 0.4844 | Acc: 0.9375
[Telemetry][L=5][Epoch 1][Iter 101] Train Loss: 0.3884 | Train Acc: 0.9688
[Telemetry][L=5][Epoch 1][Iter 106] Train Loss: 0.7136 | Train Acc: 0.7500
[Telemetry][L=5][Epoch 1] Batch 110/110 | Loss: 0.9152 | Acc: 0.7500
[Telemetry][L=5] Epoch 1 | Train Loss: 1.2352 | Train Acc: 0.7297

[Telemetry] Training with L=6 (unfreezing last 6 layers + classifier)
Unfreezing layer4
Unfreezing layer3
Unfreezing layer2
Unfreezing layer1

[Telemetry] L=6, Starting epoch 1/1
[Telemetry][L=6][Epoch 1][Iter 1] Train Loss: 3.7103 | Train Acc: 0.0625
[Telemetry][L=6][Epoch 1][Iter 6] Train Loss: 3.3019 | Train Acc: 0.1875
[Telemetry][L=6][Epoch 1][Iter 11] Train Loss: 2.6331 | Train Acc: 0.4688
[Telemetry][L=6][Epoch 1][Iter 16] Train Loss: 2.7445 | Train Acc: 0.4062
[Telemetry][L=6][Epoch 1][Iter 21] Train Loss: 1.9444 | Train Acc: 0.6250
[Telemetry][L=6][Epoch 1][Iter 26] Train Loss: 1.5385 | Train Acc: 0.7188
[Telemetry][L=6][Epoch 1][Iter 31] Train Loss: 1.3652 | Train Acc: 0.7500
[Telemetry][L=6][Epoch 1][Iter 36] Train Loss: 1.1543 | Train Acc: 0.8438
[Telemetry][L=6][Epoch 1][Iter 41] Train Loss: 1.3592 | Train Acc: 0.7188
[Telemetry][L=6][Epoch 1][Iter 46] Train Loss: 1.0206 | Train Acc: 0.8438
[Telemetry][L=6][Epoch 1][Iter 51] Train Loss: 0.9786 | Train Acc: 0.7812
[Telemetry][L=6][Epoch 1][Iter 56] Train Loss: 0.9146 | Train Acc: 0.6875
[Telemetry][L=6][Epoch 1][Iter 61] Train Loss: 0.6705 | Train Acc: 0.9062
[Telemetry][L=6][Epoch 1][Iter 66] Train Loss: 0.6378 | Train Acc: 0.9375
[Telemetry][L=6][Epoch 1][Iter 71] Train Loss: 0.8345 | Train Acc: 0.8125
[Telemetry][L=6][Epoch 1][Iter 76] Train Loss: 0.6648 | Train Acc: 0.8438
[Telemetry][L=6][Epoch 1][Iter 81] Train Loss: 0.5603 | Train Acc: 0.8750
[Telemetry][L=6][Epoch 1][Iter 86] Train Loss: 0.4473 | Train Acc: 0.8125
[Telemetry][L=6][Epoch 1][Iter 91] Train Loss: 0.4270 | Train Acc: 0.9062
[Telemetry][L=6][Epoch 1][Iter 96] Train Loss: 0.4484 | Train Acc: 0.8438
[Telemetry][L=6][Epoch 1] Batch 100/110 | Loss: 0.4197 | Acc: 0.8750
[Telemetry][L=6][Epoch 1][Iter 101] Train Loss: 0.5409 | Train Acc: 0.8750
[Telemetry][L=6][Epoch 1][Iter 106] Train Loss: 0.3274 | Train Acc: 0.9688
[Telemetry][L=6][Epoch 1] Batch 110/110 | Loss: 1.2689 | Acc: 0.6250
[Telemetry][L=6] Epoch 1 | Train Loss: 1.2037 | Train Acc: 0.7431

[Telemetry] Training with L=7 (unfreezing last 7 layers + classifier)
Unfreezing layer4
Unfreezing layer3
Unfreezing layer2
Unfreezing layer1

[Telemetry] L=7, Starting epoch 1/1
[Telemetry][L=7][Epoch 1][Iter 1] Train Loss: 4.1107 | Train Acc: 0.0000
[Telemetry][L=7][Epoch 1][Iter 6] Train Loss: 3.1688 | Train Acc: 0.1250
[Telemetry][L=7][Epoch 1][Iter 11] Train Loss: 2.5481 | Train Acc: 0.3750
[Telemetry][L=7][Epoch 1][Iter 16] Train Loss: 2.1258 | Train Acc: 0.6250
[Telemetry][L=7][Epoch 1][Iter 21] Train Loss: 1.9559 | Train Acc: 0.5625
[Telemetry][L=7][Epoch 1][Iter 26] Train Loss: 1.7234 | Train Acc: 0.6562
[Telemetry][L=7][Epoch 1][Iter 31] Train Loss: 1.4696 | Train Acc: 0.6250
[Telemetry][L=7][Epoch 1][Iter 36] Train Loss: 1.3020 | Train Acc: 0.7500
[Telemetry][L=7][Epoch 1][Iter 41] Train Loss: 0.8840 | Train Acc: 0.9688
[Telemetry][L=7][Epoch 1][Iter 46] Train Loss: 0.7428 | Train Acc: 0.9375
[Telemetry][L=7][Epoch 1][Iter 51] Train Loss: 1.0531 | Train Acc: 0.6875
[Telemetry][L=7][Epoch 1][Iter 56] Train Loss: 1.1219 | Train Acc: 0.7188
[Telemetry][L=7][Epoch 1][Iter 61] Train Loss: 0.7271 | Train Acc: 0.8750
[Telemetry][L=7][Epoch 1][Iter 66] Train Loss: 0.7440 | Train Acc: 0.8125
[Telemetry][L=7][Epoch 1][Iter 71] Train Loss: 0.6299 | Train Acc: 0.8438
[Telemetry][L=7][Epoch 1][Iter 76] Train Loss: 0.6250 | Train Acc: 0.8125
[Telemetry][L=7][Epoch 1][Iter 81] Train Loss: 0.5231 | Train Acc: 0.8750
[Telemetry][L=7][Epoch 1][Iter 86] Train Loss: 0.5562 | Train Acc: 0.9375
[Telemetry][L=7][Epoch 1][Iter 91] Train Loss: 0.4962 | Train Acc: 0.8750
[Telemetry][L=7][Epoch 1][Iter 96] Train Loss: 0.7966 | Train Acc: 0.8438
[Telemetry][L=7][Epoch 1] Batch 100/110 | Loss: 0.9337 | Acc: 0.7500
[Telemetry][L=7][Epoch 1][Iter 101] Train Loss: 0.4951 | Train Acc: 0.8750
[Telemetry][L=7][Epoch 1][Iter 106] Train Loss: 0.3897 | Train Acc: 0.9062
[Telemetry][L=7][Epoch 1] Batch 110/110 | Loss: 0.6122 | Acc: 0.8750
[Telemetry][L=7] Epoch 1 | Train Loss: 1.2071 | Train Acc: 0.7294

[Telemetry] Training with L=8 (unfreezing last 8 layers + classifier)
Unfreezing layer4
Unfreezing layer3
Unfreezing layer2
Unfreezing layer1

[Telemetry] L=8, Starting epoch 1/1
[Telemetry][L=8][Epoch 1][Iter 1] Train Loss: 3.8116 | Train Acc: 0.0625
[Telemetry][L=8][Epoch 1][Iter 6] Train Loss: 3.0393 | Train Acc: 0.2188
[Telemetry][L=8][Epoch 1][Iter 11] Train Loss: 2.8481 | Train Acc: 0.3125
[Telemetry][L=8][Epoch 1][Iter 16] Train Loss: 2.3875 | Train Acc: 0.5625
[Telemetry][L=8][Epoch 1][Iter 21] Train Loss: 1.9105 | Train Acc: 0.6562
[Telemetry][L=8][Epoch 1][Iter 26] Train Loss: 1.6429 | Train Acc: 0.6875
[Telemetry][L=8][Epoch 1][Iter 31] Train Loss: 1.4216 | Train Acc: 0.6562
[Telemetry][L=8][Epoch 1][Iter 36] Train Loss: 1.2140 | Train Acc: 0.9062
[Telemetry][L=8][Epoch 1][Iter 41] Train Loss: 1.0631 | Train Acc: 0.8438
[Telemetry][L=8][Epoch 1][Iter 46] Train Loss: 0.8396 | Train Acc: 0.9062
[Telemetry][L=8][Epoch 1][Iter 51] Train Loss: 0.6490 | Train Acc: 0.9375
[Telemetry][L=8][Epoch 1][Iter 56] Train Loss: 0.8698 | Train Acc: 0.7812
[Telemetry][L=8][Epoch 1][Iter 61] Train Loss: 0.7190 | Train Acc: 0.8438
[Telemetry][L=8][Epoch 1][Iter 66] Train Loss: 0.5191 | Train Acc: 0.9062
[Telemetry][L=8][Epoch 1][Iter 71] Train Loss: 0.8510 | Train Acc: 0.7812
[Telemetry][L=8][Epoch 1][Iter 76] Train Loss: 0.5118 | Train Acc: 0.8438
[Telemetry][L=8][Epoch 1][Iter 81] Train Loss: 0.4086 | Train Acc: 0.9062
[Telemetry][L=8][Epoch 1][Iter 86] Train Loss: 0.4218 | Train Acc: 0.9688
[Telemetry][L=8][Epoch 1][Iter 91] Train Loss: 0.4555 | Train Acc: 0.9688
[Telemetry][L=8][Epoch 1][Iter 96] Train Loss: 0.5227 | Train Acc: 0.8750
[Telemetry][L=8][Epoch 1] Batch 100/110 | Loss: 0.4748 | Acc: 0.9062
[Telemetry][L=8][Epoch 1][Iter 101] Train Loss: 0.4922 | Train Acc: 0.8750
[Telemetry][L=8][Epoch 1][Iter 106] Train Loss: 0.4810 | Train Acc: 0.8125
[Telemetry][L=8][Epoch 1] Batch 110/110 | Loss: 0.3553 | Acc: 1.0000
[Telemetry][L=8] Epoch 1 | Train Loss: 1.2043 | Train Acc: 0.7408


## Stage 2 Multi-class Classification L Comparison Run (2025-05-15_19-38-00)
### Training Loss
![](./logs\plots\stage2-multiclass-2025-05-15_19-38-00-l-comparison-loss.png)

### Training Accuracy
![](./logs\plots\stage2-multiclass-2025-05-15_19-38-00-l-comparison-acc.png)


**Log:**

[Telemetry] Number of training samples: 3496
[Telemetry] Batch size: 32
[Telemetry] Using device: cpu
[Telemetry] Strategy: simultaneous

[Telemetry] Training with L=1 (unfreezing last 1 layers + classifier)
Unfreezing layer4

[Telemetry] L=1, Starting epoch 1/1
[Telemetry][L=1][Epoch 1][Iter 1] Train Loss: 4.0157 | Train Acc: 0.0000
[Telemetry][L=1][Epoch 1][Iter 6] Train Loss: 3.2507 | Train Acc: 0.0938
[Telemetry][L=1][Epoch 1][Iter 11] Train Loss: 2.9879 | Train Acc: 0.2500
[Telemetry][L=1][Epoch 1][Iter 16] Train Loss: 2.4558 | Train Acc: 0.4375
[Telemetry][L=1][Epoch 1][Iter 21] Train Loss: 2.0999 | Train Acc: 0.5625
[Telemetry][L=1][Epoch 1][Iter 26] Train Loss: 1.6174 | Train Acc: 0.7812
[Telemetry][L=1][Epoch 1][Iter 31] Train Loss: 1.2643 | Train Acc: 0.7500
[Telemetry][L=1][Epoch 1][Iter 36] Train Loss: 1.3743 | Train Acc: 0.7500
[Telemetry][L=1][Epoch 1][Iter 41] Train Loss: 1.2583 | Train Acc: 0.7500
[Telemetry][L=1][Epoch 1][Iter 46] Train Loss: 0.8165 | Train Acc: 0.9375
[Telemetry][L=1][Epoch 1][Iter 51] Train Loss: 0.9159 | Train Acc: 0.8750
[Telemetry][L=1][Epoch 1][Iter 56] Train Loss: 0.8765 | Train Acc: 0.8438
[Telemetry][L=1][Epoch 1][Iter 61] Train Loss: 0.8951 | Train Acc: 0.7812
[Telemetry][L=1][Epoch 1][Iter 66] Train Loss: 0.7534 | Train Acc: 0.9062
[Telemetry][L=1][Epoch 1][Iter 71] Train Loss: 0.7253 | Train Acc: 0.8750
[Telemetry][L=1][Epoch 1][Iter 76] Train Loss: 0.7437 | Train Acc: 0.8438
[Telemetry][L=1][Epoch 1][Iter 81] Train Loss: 0.7345 | Train Acc: 0.8750
[Telemetry][L=1][Epoch 1][Iter 86] Train Loss: 0.5450 | Train Acc: 0.9375
[Telemetry][L=1][Epoch 1][Iter 91] Train Loss: 0.4121 | Train Acc: 1.0000
[Telemetry][L=1][Epoch 1][Iter 96] Train Loss: 0.6286 | Train Acc: 0.8125
[Telemetry][L=1][Epoch 1] Batch 100/110 | Loss: 0.7707 | Acc: 0.7500
[Telemetry][L=1][Epoch 1][Iter 101] Train Loss: 0.5280 | Train Acc: 0.9062
[Telemetry][L=1][Epoch 1][Iter 106] Train Loss: 0.5674 | Train Acc: 0.8750
[Telemetry][L=1][Epoch 1] Batch 110/110 | Loss: 1.1162 | Acc: 0.7500
[Telemetry][L=1] Epoch 1 | Train Loss: 1.2907 | Train Acc: 0.7288

[Telemetry] Training with L=2 (unfreezing last 2 layers + classifier)
Unfreezing layer4
Unfreezing layer3

[Telemetry] L=2, Starting epoch 1/1
[Telemetry][L=2][Epoch 1][Iter 1] Train Loss: 3.8492 | Train Acc: 0.0625
[Telemetry][L=2][Epoch 1][Iter 6] Train Loss: 3.2768 | Train Acc: 0.1562
[Telemetry][L=2][Epoch 1][Iter 11] Train Loss: 2.6950 | Train Acc: 0.3125
[Telemetry][L=2][Epoch 1][Iter 16] Train Loss: 2.1929 | Train Acc: 0.5000
[Telemetry][L=2][Epoch 1][Iter 21] Train Loss: 1.6626 | Train Acc: 0.8125
[Telemetry][L=2][Epoch 1][Iter 26] Train Loss: 1.5770 | Train Acc: 0.6875
[Telemetry][L=2][Epoch 1][Iter 31] Train Loss: 1.3608 | Train Acc: 0.8125
[Telemetry][L=2][Epoch 1][Iter 36] Train Loss: 1.0508 | Train Acc: 0.8438
[Telemetry][L=2][Epoch 1][Iter 41] Train Loss: 1.1614 | Train Acc: 0.7812
[Telemetry][L=2][Epoch 1][Iter 46] Train Loss: 1.0076 | Train Acc: 0.8125
[Telemetry][L=2][Epoch 1][Iter 51] Train Loss: 0.7298 | Train Acc: 0.9062
[Telemetry][L=2][Epoch 1][Iter 56] Train Loss: 0.7887 | Train Acc: 0.8438
[Telemetry][L=2][Epoch 1][Iter 61] Train Loss: 0.7057 | Train Acc: 0.8438
[Telemetry][L=2][Epoch 1][Iter 66] Train Loss: 0.6395 | Train Acc: 0.8438
[Telemetry][L=2][Epoch 1][Iter 71] Train Loss: 0.5804 | Train Acc: 0.9062
[Telemetry][L=2][Epoch 1][Iter 76] Train Loss: 0.4833 | Train Acc: 0.9062
[Telemetry][L=2][Epoch 1][Iter 81] Train Loss: 0.5507 | Train Acc: 0.8750
[Telemetry][L=2][Epoch 1][Iter 86] Train Loss: 0.7698 | Train Acc: 0.7812
[Telemetry][L=2][Epoch 1][Iter 91] Train Loss: 0.4888 | Train Acc: 0.9375
[Telemetry][L=2][Epoch 1][Iter 96] Train Loss: 0.4737 | Train Acc: 0.9062
[Telemetry][L=2][Epoch 1] Batch 100/110 | Loss: 0.4245 | Acc: 0.8750
[Telemetry][L=2][Epoch 1][Iter 101] Train Loss: 0.4894 | Train Acc: 0.9062
[Telemetry][L=2][Epoch 1][Iter 106] Train Loss: 0.5489 | Train Acc: 0.8750
[Telemetry][L=2][Epoch 1] Batch 110/110 | Loss: 1.3177 | Acc: 0.5000
[Telemetry][L=2] Epoch 1 | Train Loss: 1.2200 | Train Acc: 0.7331

[Telemetry] Training with L=3 (unfreezing last 3 layers + classifier)
Unfreezing layer4
Unfreezing layer3
Unfreezing layer2

[Telemetry] L=3, Starting epoch 1/1
[Telemetry][L=3][Epoch 1][Iter 1] Train Loss: 3.7221 | Train Acc: 0.0625
[Telemetry][L=3][Epoch 1][Iter 6] Train Loss: 3.0800 | Train Acc: 0.2188
[Telemetry][L=3][Epoch 1][Iter 11] Train Loss: 2.7529 | Train Acc: 0.3125
[Telemetry][L=3][Epoch 1][Iter 16] Train Loss: 2.3615 | Train Acc: 0.5625
[Telemetry][L=3][Epoch 1][Iter 21] Train Loss: 1.9899 | Train Acc: 0.6250
[Telemetry][L=3][Epoch 1][Iter 26] Train Loss: 1.5341 | Train Acc: 0.6562
[Telemetry][L=3][Epoch 1][Iter 31] Train Loss: 1.5709 | Train Acc: 0.6875
[Telemetry][L=3][Epoch 1][Iter 36] Train Loss: 1.1590 | Train Acc: 0.7188
[Telemetry][L=3][Epoch 1][Iter 41] Train Loss: 1.2230 | Train Acc: 0.6562
[Telemetry][L=3][Epoch 1][Iter 46] Train Loss: 1.0215 | Train Acc: 0.7188
[Telemetry][L=3][Epoch 1][Iter 51] Train Loss: 0.7912 | Train Acc: 0.9062
[Telemetry][L=3][Epoch 1][Iter 56] Train Loss: 0.4483 | Train Acc: 0.9375
[Telemetry][L=3][Epoch 1][Iter 61] Train Loss: 0.4740 | Train Acc: 0.9062
[Telemetry][L=3][Epoch 1][Iter 66] Train Loss: 0.5298 | Train Acc: 0.9375
[Telemetry][L=3][Epoch 1][Iter 71] Train Loss: 0.7339 | Train Acc: 0.8438
[Telemetry][L=3][Epoch 1][Iter 76] Train Loss: 0.5379 | Train Acc: 0.9062
[Telemetry][L=3][Epoch 1][Iter 81] Train Loss: 0.6585 | Train Acc: 0.7812
[Telemetry][L=3][Epoch 1][Iter 86] Train Loss: 0.5970 | Train Acc: 0.8750
[Telemetry][L=3][Epoch 1][Iter 91] Train Loss: 0.6544 | Train Acc: 0.7500
[Telemetry][L=3][Epoch 1][Iter 96] Train Loss: 0.4977 | Train Acc: 0.9062
[Telemetry][L=3][Epoch 1] Batch 100/110 | Loss: 0.3342 | Acc: 0.9375
[Telemetry][L=3][Epoch 1][Iter 101] Train Loss: 0.4091 | Train Acc: 0.9062
[Telemetry][L=3][Epoch 1][Iter 106] Train Loss: 0.5574 | Train Acc: 0.8750
[Telemetry][L=3][Epoch 1] Batch 110/110 | Loss: 0.5065 | Acc: 1.0000
[Telemetry][L=3] Epoch 1 | Train Loss: 1.2013 | Train Acc: 0.7320

[Telemetry] Training with L=4 (unfreezing last 4 layers + classifier)
Unfreezing layer4
Unfreezing layer3
Unfreezing layer2
Unfreezing layer1

[Telemetry] L=4, Starting epoch 1/1
[Telemetry][L=4][Epoch 1][Iter 1] Train Loss: 4.0826 | Train Acc: 0.0000
[Telemetry][L=4][Epoch 1][Iter 6] Train Loss: 3.4517 | Train Acc: 0.1562
[Telemetry][L=4][Epoch 1][Iter 11] Train Loss: 2.6938 | Train Acc: 0.3125
[Telemetry][L=4][Epoch 1][Iter 16] Train Loss: 2.3311 | Train Acc: 0.5312
[Telemetry][L=4][Epoch 1][Iter 21] Train Loss: 1.8939 | Train Acc: 0.6562
[Telemetry][L=4][Epoch 1][Iter 26] Train Loss: 1.7167 | Train Acc: 0.6562
[Telemetry][L=4][Epoch 1][Iter 31] Train Loss: 1.5178 | Train Acc: 0.6875
[Telemetry][L=4][Epoch 1][Iter 36] Train Loss: 1.1079 | Train Acc: 0.8125
[Telemetry][L=4][Epoch 1][Iter 41] Train Loss: 1.0727 | Train Acc: 0.8125
[Telemetry][L=4][Epoch 1][Iter 46] Train Loss: 0.9624 | Train Acc: 0.7500
[Telemetry][L=4][Epoch 1][Iter 51] Train Loss: 0.8261 | Train Acc: 0.7812
[Telemetry][L=4][Epoch 1][Iter 56] Train Loss: 0.7528 | Train Acc: 0.8438
[Telemetry][L=4][Epoch 1][Iter 61] Train Loss: 0.7713 | Train Acc: 0.8438
[Telemetry][L=4][Epoch 1][Iter 66] Train Loss: 0.5334 | Train Acc: 0.9062
[Telemetry][L=4][Epoch 1][Iter 71] Train Loss: 0.5574 | Train Acc: 0.9688
[Telemetry][L=4][Epoch 1][Iter 76] Train Loss: 0.4639 | Train Acc: 0.9375
[Telemetry][L=4][Epoch 1][Iter 81] Train Loss: 0.4443 | Train Acc: 0.9062
[Telemetry][L=4][Epoch 1][Iter 86] Train Loss: 0.8327 | Train Acc: 0.7812
[Telemetry][L=4][Epoch 1][Iter 91] Train Loss: 0.4467 | Train Acc: 0.9062
[Telemetry][L=4][Epoch 1][Iter 96] Train Loss: 0.7615 | Train Acc: 0.8125
[Telemetry][L=4][Epoch 1] Batch 100/110 | Loss: 0.6923 | Acc: 0.8438
[Telemetry][L=4][Epoch 1][Iter 101] Train Loss: 0.3515 | Train Acc: 0.9062
[Telemetry][L=4][Epoch 1][Iter 106] Train Loss: 0.4270 | Train Acc: 0.9062
[Telemetry][L=4][Epoch 1] Batch 110/110 | Loss: 1.0151 | Acc: 0.6250
[Telemetry][L=4] Epoch 1 | Train Loss: 1.2011 | Train Acc: 0.7340


## Stage 2 Multi-class Classification Block Comparison Run (2025-05-15_20-36-57)
### Training Loss (Layer4 Block Unfreezing)
![](./logs\plots\stage2-multiclass-2025-05-15_20-36-57-blocks-comparison-loss.png)

### Training Accuracy (Layer4 Block Unfreezing)
![](./logs\plots\stage2-multiclass-2025-05-15_20-36-57-blocks-comparison-acc.png)


**Log:**

[Telemetry] Number of training samples: 3496
[Telemetry] Batch size: 32
[Telemetry] Using device: cpu
[Telemetry] Strategy: simultaneous

[Telemetry] Training with 1 blocks unfrozen in layer4 + classifier
Total blocks in layer4: 3
Unfreezing layer4.block2
Unfrozen blocks in layer4: [2]

[Telemetry] Blocks=1, Starting epoch 1/1
[Telemetry][Blocks=1][Epoch 1][Iter 1] Train Loss: 3.5352 | Train Acc: 0.0625
[Telemetry][Blocks=1][Epoch 1][Iter 6] Train Loss: 3.7752 | Train Acc: 0.0625
[Telemetry][Blocks=1][Epoch 1][Iter 11] Train Loss: 3.2475 | Train Acc: 0.1875
[Telemetry][Blocks=1][Epoch 1][Iter 16] Train Loss: 2.9165 | Train Acc: 0.2812
[Telemetry][Blocks=1][Epoch 1][Iter 21] Train Loss: 2.4344 | Train Acc: 0.5312
[Telemetry][Blocks=1][Epoch 1][Iter 26] Train Loss: 2.1487 | Train Acc: 0.5938
[Telemetry][Blocks=1][Epoch 1][Iter 31] Train Loss: 2.2500 | Train Acc: 0.5938
[Telemetry][Blocks=1][Epoch 1][Iter 36] Train Loss: 1.8944 | Train Acc: 0.5938
[Telemetry][Blocks=1][Epoch 1][Iter 41] Train Loss: 1.6592 | Train Acc: 0.6875
[Telemetry][Blocks=1][Epoch 1][Iter 46] Train Loss: 1.3819 | Train Acc: 0.7500
[Telemetry][Blocks=1][Epoch 1][Iter 51] Train Loss: 1.2082 | Train Acc: 0.8125
[Telemetry][Blocks=1][Epoch 1][Iter 56] Train Loss: 1.1227 | Train Acc: 0.9062
[Telemetry][Blocks=1][Epoch 1][Iter 61] Train Loss: 1.2153 | Train Acc: 0.8125
[Telemetry][Blocks=1][Epoch 1][Iter 66] Train Loss: 1.1110 | Train Acc: 0.8438
[Telemetry][Blocks=1][Epoch 1][Iter 71] Train Loss: 1.0816 | Train Acc: 0.8438
[Telemetry][Blocks=1][Epoch 1][Iter 76] Train Loss: 1.0137 | Train Acc: 0.9375
[Telemetry][Blocks=1][Epoch 1][Iter 81] Train Loss: 1.2005 | Train Acc: 0.6875
[Telemetry][Blocks=1][Epoch 1][Iter 86] Train Loss: 1.0061 | Train Acc: 0.8438
[Telemetry][Blocks=1][Epoch 1][Iter 91] Train Loss: 0.9247 | Train Acc: 0.9062
[Telemetry][Blocks=1][Epoch 1][Iter 96] Train Loss: 0.8727 | Train Acc: 0.9062
[Telemetry][Blocks=1][Epoch 1] Batch 100/110 | Loss: 0.7818 | Acc: 0.8438
[Telemetry][Blocks=1][Epoch 1][Iter 101] Train Loss: 0.7300 | Train Acc: 0.9062
[Telemetry][Blocks=1][Epoch 1][Iter 106] Train Loss: 1.0257 | Train Acc: 0.7188
[Telemetry][Blocks=1][Epoch 1] Batch 110/110 | Loss: 1.1977 | Acc: 0.7500
[Telemetry][Blocks=1] Epoch 1 | Train Loss: 1.6850 | Train Acc: 0.6676

[Telemetry] Training with 2 blocks unfrozen in layer4 + classifier
Total blocks in layer4: 3
Unfreezing layer4.block2
Unfreezing layer4.block1
Unfrozen blocks in layer4: [1, 2]

[Telemetry] Blocks=2, Starting epoch 1/1
[Telemetry][Blocks=2][Epoch 1][Iter 1] Train Loss: 3.7073 | Train Acc: 0.0625
[Telemetry][Blocks=2][Epoch 1][Iter 6] Train Loss: 3.3530 | Train Acc: 0.1562
[Telemetry][Blocks=2][Epoch 1][Iter 11] Train Loss: 2.9348 | Train Acc: 0.2812
[Telemetry][Blocks=2][Epoch 1][Iter 16] Train Loss: 2.4312 | Train Acc: 0.4375
[Telemetry][Blocks=2][Epoch 1][Iter 21] Train Loss: 2.2962 | Train Acc: 0.5938
[Telemetry][Blocks=2][Epoch 1][Iter 26] Train Loss: 2.1040 | Train Acc: 0.6562
[Telemetry][Blocks=2][Epoch 1][Iter 31] Train Loss: 1.7228 | Train Acc: 0.6250
[Telemetry][Blocks=2][Epoch 1][Iter 36] Train Loss: 1.4870 | Train Acc: 0.6875
[Telemetry][Blocks=2][Epoch 1][Iter 41] Train Loss: 1.4360 | Train Acc: 0.7188
[Telemetry][Blocks=2][Epoch 1][Iter 46] Train Loss: 1.1681 | Train Acc: 0.7500
[Telemetry][Blocks=2][Epoch 1][Iter 51] Train Loss: 1.0348 | Train Acc: 0.8125
[Telemetry][Blocks=2][Epoch 1][Iter 56] Train Loss: 1.0951 | Train Acc: 0.7812
[Telemetry][Blocks=2][Epoch 1][Iter 61] Train Loss: 0.9672 | Train Acc: 0.7812
[Telemetry][Blocks=2][Epoch 1][Iter 66] Train Loss: 0.8051 | Train Acc: 0.8750
[Telemetry][Blocks=2][Epoch 1][Iter 71] Train Loss: 0.7888 | Train Acc: 0.8750
[Telemetry][Blocks=2][Epoch 1][Iter 76] Train Loss: 0.9983 | Train Acc: 0.7188
[Telemetry][Blocks=2][Epoch 1][Iter 81] Train Loss: 0.6489 | Train Acc: 0.8125
[Telemetry][Blocks=2][Epoch 1][Iter 86] Train Loss: 0.6187 | Train Acc: 0.8750
[Telemetry][Blocks=2][Epoch 1][Iter 91] Train Loss: 0.7450 | Train Acc: 0.8125
[Telemetry][Blocks=2][Epoch 1][Iter 96] Train Loss: 0.5069 | Train Acc: 0.9375
[Telemetry][Blocks=2][Epoch 1] Batch 100/110 | Loss: 0.6124 | Acc: 0.9375
[Telemetry][Blocks=2][Epoch 1][Iter 101] Train Loss: 0.7515 | Train Acc: 0.8750
[Telemetry][Blocks=2][Epoch 1][Iter 106] Train Loss: 0.5161 | Train Acc: 0.9062
[Telemetry][Blocks=2][Epoch 1] Batch 110/110 | Loss: 0.5599 | Acc: 0.8750
[Telemetry][Blocks=2] Epoch 1 | Train Loss: 1.3799 | Train Acc: 0.7082

[Telemetry] Training with 3 blocks unfrozen in layer4 + classifier
Total blocks in layer4: 3
Unfreezing layer4.block2
Unfreezing layer4.block1
Unfreezing layer4.block0
Unfrozen blocks in layer4: [0, 1, 2]

[Telemetry] Blocks=3, Starting epoch 1/1
[Telemetry][Blocks=3][Epoch 1][Iter 1] Train Loss: 4.0235 | Train Acc: 0.0000
[Telemetry][Blocks=3][Epoch 1][Iter 6] Train Loss: 3.5781 | Train Acc: 0.0938
[Telemetry][Blocks=3][Epoch 1][Iter 11] Train Loss: 2.7686 | Train Acc: 0.3438
[Telemetry][Blocks=3][Epoch 1][Iter 16] Train Loss: 2.2260 | Train Acc: 0.5000
[Telemetry][Blocks=3][Epoch 1][Iter 21] Train Loss: 2.1793 | Train Acc: 0.4375
[Telemetry][Blocks=3][Epoch 1][Iter 26] Train Loss: 1.6606 | Train Acc: 0.7188
[Telemetry][Blocks=3][Epoch 1][Iter 31] Train Loss: 1.3949 | Train Acc: 0.7500
[Telemetry][Blocks=3][Epoch 1][Iter 36] Train Loss: 1.3977 | Train Acc: 0.7188
[Telemetry][Blocks=3][Epoch 1][Iter 41] Train Loss: 1.5184 | Train Acc: 0.6250
[Telemetry][Blocks=3][Epoch 1][Iter 46] Train Loss: 0.8619 | Train Acc: 0.8438
[Telemetry][Blocks=3][Epoch 1][Iter 51] Train Loss: 0.9763 | Train Acc: 0.8438
[Telemetry][Blocks=3][Epoch 1][Iter 56] Train Loss: 0.7984 | Train Acc: 0.8750
[Telemetry][Blocks=3][Epoch 1][Iter 61] Train Loss: 0.5971 | Train Acc: 0.9375
[Telemetry][Blocks=3][Epoch 1][Iter 66] Train Loss: 0.7118 | Train Acc: 0.8125
[Telemetry][Blocks=3][Epoch 1][Iter 71] Train Loss: 0.9426 | Train Acc: 0.8125
[Telemetry][Blocks=3][Epoch 1][Iter 76] Train Loss: 0.8482 | Train Acc: 0.6875
[Telemetry][Blocks=3][Epoch 1][Iter 81] Train Loss: 0.5802 | Train Acc: 0.9375
[Telemetry][Blocks=3][Epoch 1][Iter 86] Train Loss: 0.6616 | Train Acc: 0.8438
[Telemetry][Blocks=3][Epoch 1][Iter 91] Train Loss: 0.7382 | Train Acc: 0.8438
[Telemetry][Blocks=3][Epoch 1][Iter 96] Train Loss: 0.5218 | Train Acc: 0.9062
[Telemetry][Blocks=3][Epoch 1] Batch 100/110 | Loss: 0.5813 | Acc: 0.8438
[Telemetry][Blocks=3][Epoch 1][Iter 101] Train Loss: 0.4877 | Train Acc: 0.9062
[Telemetry][Blocks=3][Epoch 1][Iter 106] Train Loss: 0.6006 | Train Acc: 0.9062
[Telemetry][Blocks=3][Epoch 1] Batch 110/110 | Loss: 0.4154 | Acc: 1.0000
[Telemetry][Blocks=3] Epoch 1 | Train Loss: 1.2701 | Train Acc: 0.7234


## Stage 2 Multi-class Classification with Gradual Unfreezing (2025-05-15_21-34-47)
### Training Loss (Gradual Unfreezing)
![](./logs\plots\stage2-multiclass-2025-05-15_21-34-47-gradual-loss.png)

### Training Accuracy (Gradual Unfreezing)
![](./logs\plots\stage2-multiclass-2025-05-15_21-34-47-gradual-acc.png)


**Training Log:**

[Telemetry] Number of training samples: 3496
[Telemetry] Batch size: 32
[Telemetry] Using device: cpu
[Telemetry] Strategy: gradual

[Telemetry] Starting training with gradual unfreezing

[Telemetry] Starting epoch 1/1
Progress: 0.9% - Unfrozen 1 blocks in layer4
[Epoch 1][Iter 1] Loss: 3.9672 | Acc: 0.0625
[Epoch 1][Iter 6] Loss: 3.4097 | Acc: 0.1250
[Epoch 1] Batch 10/110 | Blocks: 1 | Loss: 3.5170 | Acc: 0.1562
[Epoch 1][Iter 11] Loss: 3.0168 | Acc: 0.2188
[Epoch 1][Iter 16] Loss: 2.9129 | Acc: 0.2188
[Epoch 1] Batch 20/110 | Blocks: 1 | Loss: 2.5259 | Acc: 0.4375
[Epoch 1][Iter 21] Loss: 2.6491 | Acc: 0.3438
[Epoch 1][Iter 26] Loss: 2.4155 | Acc: 0.4688
[Epoch 1] Batch 30/110 | Blocks: 1 | Loss: 2.1655 | Acc: 0.5938
[Epoch 1][Iter 31] Loss: 2.0243 | Acc: 0.5938
[Epoch 1][Iter 36] Loss: 1.9044 | Acc: 0.6562
Progress: 33.6% - Unfrozen 2 blocks in layer4
[Epoch 1] Batch 40/110 | Blocks: 2 | Loss: 1.6482 | Acc: 0.6562
[Epoch 1][Iter 41] Loss: 1.5883 | Acc: 0.8438
[Epoch 1][Iter 46] Loss: 1.4380 | Acc: 0.7812
[Epoch 1] Batch 50/110 | Blocks: 2 | Loss: 1.2402 | Acc: 0.8438
[Epoch 1][Iter 51] Loss: 1.1233 | Acc: 0.8125
[Epoch 1][Iter 56] Loss: 1.0524 | Acc: 0.8125
[Epoch 1] Batch 60/110 | Blocks: 2 | Loss: 1.3679 | Acc: 0.6250
[Epoch 1][Iter 61] Loss: 0.9502 | Acc: 0.7812
[Epoch 1][Iter 66] Loss: 0.9030 | Acc: 0.8438
[Epoch 1] Batch 70/110 | Blocks: 2 | Loss: 0.7896 | Acc: 0.8438
[Epoch 1][Iter 71] Loss: 0.9629 | Acc: 0.8438
Progress: 67.3% - Unfrozen 3 blocks in layer4
[Epoch 1][Iter 76] Loss: 0.8654 | Acc: 0.8750
[Epoch 1] Batch 80/110 | Blocks: 3 | Loss: 0.6473 | Acc: 0.9062
[Epoch 1][Iter 81] Loss: 0.8189 | Acc: 0.8125
[Epoch 1][Iter 86] Loss: 0.8642 | Acc: 0.8438
[Epoch 1] Batch 90/110 | Blocks: 3 | Loss: 0.6664 | Acc: 0.9062
[Epoch 1][Iter 91] Loss: 0.5908 | Acc: 0.9375
[Epoch 1][Iter 96] Loss: 0.5229 | Acc: 0.8750
[Epoch 1] Batch 100/110 | Blocks: 3 | Loss: 0.4113 | Acc: 0.9375
[Epoch 1][Iter 101] Loss: 0.5885 | Acc: 0.8125
[Epoch 1][Iter 106] Loss: 0.5990 | Acc: 0.8438
[Epoch 1] Batch 110/110 | Blocks: 3 | Loss: 1.1994 | Acc: 0.6250
[Telemetry] Epoch 1 | Train Loss: 1.5681 | Train Acc: 0.6628


## Stage 2 Multi-class Classification with Gradual Unfreezing (2025-05-15_21-40-29)
### Training Loss (Gradual Unfreezing)
![](./logs\plots\stage2-multiclass-2025-05-15_21-40-29-gradual-loss.png)

### Training Accuracy (Gradual Unfreezing)
![](./logs\plots\stage2-multiclass-2025-05-15_21-40-29-gradual-acc.png)


**Training Log:**

[Telemetry] Number of training samples: 3496
[Telemetry] Batch size: 32
[Telemetry] Using device: cpu
[Telemetry] Strategy: gradual

[Telemetry] Starting training with gradual unfreezing

[Telemetry] Starting epoch 1/1
Progress: 0.9% - Unfrozen 1 blocks in layer4
[Epoch 1][Iter 1] Loss: 3.8610 | Acc: 0.0000
[Epoch 1][Iter 6] Loss: 3.3726 | Acc: 0.1562
[Epoch 1] Batch 10/110 | Blocks: 1 | Loss: 3.0302 | Acc: 0.2500
[Epoch 1][Iter 11] Loss: 3.0676 | Acc: 0.1875
[Epoch 1][Iter 16] Loss: 2.8096 | Acc: 0.3125
[Epoch 1] Batch 20/110 | Blocks: 1 | Loss: 2.6667 | Acc: 0.3750
[Epoch 1][Iter 21] Loss: 2.3628 | Acc: 0.4375
[Epoch 1][Iter 26] Loss: 2.4851 | Acc: 0.4375
[Epoch 1] Batch 30/110 | Blocks: 1 | Loss: 2.3459 | Acc: 0.3750
[Epoch 1][Iter 31] Loss: 2.1758 | Acc: 0.5000
[Epoch 1][Iter 36] Loss: 1.9225 | Acc: 0.6250
Progress: 33.6% - Unfrozen 2 blocks in layer4
[Epoch 1] Batch 40/110 | Blocks: 2 | Loss: 1.9325 | Acc: 0.5938
[Epoch 1][Iter 41] Loss: 1.5418 | Acc: 0.7500
[Epoch 1][Iter 46] Loss: 1.3858 | Acc: 0.7812
[Epoch 1] Batch 50/110 | Blocks: 2 | Loss: 1.2850 | Acc: 0.7500
[Epoch 1][Iter 51] Loss: 1.3953 | Acc: 0.7812
[Epoch 1][Iter 56] Loss: 1.2375 | Acc: 0.7812
[Epoch 1] Batch 60/110 | Blocks: 2 | Loss: 0.9667 | Acc: 0.7812
[Epoch 1][Iter 61] Loss: 1.0420 | Acc: 0.7812
[Epoch 1][Iter 66] Loss: 1.0110 | Acc: 0.8125
[Epoch 1] Batch 70/110 | Blocks: 2 | Loss: 0.8820 | Acc: 0.8750
[Epoch 1][Iter 71] Loss: 1.0495 | Acc: 0.7812
Progress: 67.3% - Unfrozen 3 blocks in layer4
[Epoch 1][Iter 76] Loss: 0.9343 | Acc: 0.8438
[Epoch 1] Batch 80/110 | Blocks: 3 | Loss: 0.8470 | Acc: 0.8125
[Epoch 1][Iter 81] Loss: 0.8453 | Acc: 0.8125
[Epoch 1][Iter 86] Loss: 0.7027 | Acc: 0.8438
[Epoch 1] Batch 90/110 | Blocks: 3 | Loss: 0.5782 | Acc: 0.8750
[Epoch 1][Iter 91] Loss: 0.6328 | Acc: 0.8750
[Epoch 1][Iter 96] Loss: 0.5335 | Acc: 0.8750
[Epoch 1] Batch 100/110 | Blocks: 3 | Loss: 0.5529 | Acc: 0.9688
[Epoch 1][Iter 101] Loss: 0.6435 | Acc: 0.8750
[Epoch 1][Iter 106] Loss: 0.6297 | Acc: 0.8438
[Epoch 1] Batch 110/110 | Blocks: 3 | Loss: 0.8320 | Acc: 0.7500
[Telemetry] Epoch 1 | Train Loss: 1.5406 | Train Acc: 0.6693


## Stage 2 Multi-class Classification with Gradual Unfreezing (2025-05-15_21-48-38)
### Training Loss (Gradual Unfreezing)
![](./logs\plots\stage2-multiclass-2025-05-15_21-48-38-gradual-loss.png)

### Training Accuracy (Gradual Unfreezing)
![](./logs\plots\stage2-multiclass-2025-05-15_21-48-38-gradual-acc.png)


**Training Log:**

[Telemetry] Number of training samples: 184
[Telemetry] Batch size: 32
[Telemetry] Using device: cpu
[Telemetry] Strategy: gradual

[Telemetry] Starting training with gradual unfreezing

[Telemetry] Starting epoch 1/1
Progress: 16.7% - Unfrozen 1 blocks in layer4
[Epoch 1][Iter 1] Loss: 3.7620 | Acc: 0.0312
Progress: 33.3% - Unfrozen 2 blocks in layer4
Progress: 66.7% - Unfrozen 3 blocks in layer4
[Epoch 1][Iter 6] Loss: 3.3630 | Acc: 0.2083
[Epoch 1] Batch 6/6 | Blocks: 3 | Loss: 3.3630 | Acc: 0.2083
[Telemetry] Epoch 1 | Train Loss: 3.6729 | Train Acc: 0.0652


## Stage 2 Multi-class Classification with Gradual Unfreezing (2025-05-15_21-49-55)
### Training Loss (Gradual Unfreezing)
![](./logs\plots\stage2-multiclass-2025-05-15_21-49-55-gradual-loss.png)

### Training Accuracy (Gradual Unfreezing)
![](./logs\plots\stage2-multiclass-2025-05-15_21-49-55-gradual-acc.png)


**Training Log:**

[Telemetry] Number of training samples: 3496
[Telemetry] Batch size: 32
[Telemetry] Using device: cpu
[Telemetry] Strategy: gradual

[Telemetry] Starting training with gradual unfreezing

[Telemetry] Starting epoch 1/1
Progress: 0.9% - Unfrozen 1 blocks in layer4
[Epoch 1][Iter 1] Loss: 3.5408 | Acc: 0.0938
[Epoch 1][Iter 6] Loss: 3.4916 | Acc: 0.0625
[Epoch 1] Batch 10/110 | Blocks: 1 | Loss: 3.0971 | Acc: 0.1562
[Epoch 1][Iter 11] Loss: 3.4301 | Acc: 0.0938
[Epoch 1][Iter 16] Loss: 2.7194 | Acc: 0.2812
[Epoch 1] Batch 20/110 | Blocks: 1 | Loss: 2.5587 | Acc: 0.4688
[Epoch 1][Iter 21] Loss: 2.4305 | Acc: 0.5625
[Epoch 1][Iter 26] Loss: 2.2706 | Acc: 0.6250
[Epoch 1] Batch 30/110 | Blocks: 1 | Loss: 2.1580 | Acc: 0.5938
[Epoch 1][Iter 31] Loss: 2.1724 | Acc: 0.5625
[Epoch 1][Iter 36] Loss: 1.7600 | Acc: 0.6875
Progress: 33.6% - Unfrozen 2 blocks in layer4
[Epoch 1] Batch 40/110 | Blocks: 2 | Loss: 1.5827 | Acc: 0.6250
[Epoch 1][Iter 41] Loss: 1.7406 | Acc: 0.6875
[Epoch 1][Iter 46] Loss: 1.6514 | Acc: 0.6562
[Epoch 1] Batch 50/110 | Blocks: 2 | Loss: 1.4433 | Acc: 0.6250
[Epoch 1][Iter 51] Loss: 1.0777 | Acc: 0.8438
[Epoch 1][Iter 56] Loss: 1.0190 | Acc: 0.8438
[Epoch 1] Batch 60/110 | Blocks: 2 | Loss: 1.1078 | Acc: 0.8750
[Epoch 1][Iter 61] Loss: 1.0130 | Acc: 0.8438
[Epoch 1][Iter 66] Loss: 1.1724 | Acc: 0.7500
[Epoch 1] Batch 70/110 | Blocks: 2 | Loss: 0.8280 | Acc: 0.8125
[Epoch 1][Iter 71] Loss: 0.7693 | Acc: 0.8438
Progress: 67.3% - Unfrozen 3 blocks in layer4
[Epoch 1][Iter 76] Loss: 0.7317 | Acc: 0.8438
[Epoch 1] Batch 80/110 | Blocks: 3 | Loss: 0.8238 | Acc: 0.9062
[Epoch 1][Iter 81] Loss: 0.6236 | Acc: 0.8750
[Epoch 1][Iter 86] Loss: 0.8655 | Acc: 0.7812
[Epoch 1] Batch 90/110 | Blocks: 3 | Loss: 0.7899 | Acc: 0.7812
[Epoch 1][Iter 91] Loss: 0.6264 | Acc: 0.8438
[Epoch 1][Iter 96] Loss: 0.5316 | Acc: 0.8750
[Epoch 1] Batch 100/110 | Blocks: 3 | Loss: 0.6394 | Acc: 0.8750
[Epoch 1][Iter 101] Loss: 0.8217 | Acc: 0.8125
[Epoch 1][Iter 106] Loss: 0.5988 | Acc: 0.8438
[Epoch 1] Batch 110/110 | Blocks: 3 | Loss: 0.6288 | Acc: 0.7500
[Telemetry] Epoch 1 | Train Loss: 1.5386 | Train Acc: 0.6648


## Stage 2 Multi-class Classification Block Comparison Run (2025-05-15_22-43-35)
### Training Loss per Iteration (Layer4 Block Unfreezing)
![](./logs\plots\stage2-multiclass-2025-05-15_22-43-35-blocks-comparison-loss-train.png)

### Training Accuracy per Iteration (Layer4 Block Unfreezing)
![](./logs\plots\stage2-multiclass-2025-05-15_22-43-35-blocks-comparison-acc-train.png)

### Validation Loss per Iteration (Layer4 Block Unfreezing)
![](./logs\plots\stage2-multiclass-2025-05-15_22-43-35-blocks-comparison-val-loss.png)

### Validation Accuracy per Iteration (Layer4 Block Unfreezing)
![](./logs\plots\stage2-multiclass-2025-05-15_22-43-35-blocks-comparison-val-acc.png)

### Training vs Validation Loss per Epoch (Layer4 Block Unfreezing)
![](./logs\plots\stage2-multiclass-2025-05-15_22-43-35-blocks-comparison-train-vs-val-loss.png)

### Training vs Validation Accuracy per Epoch (Layer4 Block Unfreezing)
![](./logs\plots\stage2-multiclass-2025-05-15_22-43-35-blocks-comparison-train-vs-val-acc.png)


**Log:**

[Telemetry] Number of training samples: 3312
[Telemetry] Batch size: 32
[Telemetry] Using device: cpu
[Telemetry] Strategy: simultaneous
[Telemetry] Number of validation samples: 368

[Telemetry] Training with 1 blocks unfrozen in layer4 + classifier
Total blocks in layer4: 3
Unfreezing layer4.block2
Unfrozen blocks in layer4: [2]

[Telemetry] Blocks=1, Starting epoch 1/1
[Telemetry][Blocks=1][Epoch 1][Iter 1] Train Loss: 3.9328 | Train Acc: 0.0000 | Val Loss: 3.7258 | Val Acc: 0.0312
[Telemetry][Blocks=1][Epoch 1][Iter 6] Train Loss: 3.6536 | Train Acc: 0.0312 | Val Loss: 3.5139 | Val Acc: 0.0000
[Telemetry][Blocks=1][Epoch 1][Iter 11] Train Loss: 3.0894 | Train Acc: 0.1562 | Val Loss: 2.9593 | Val Acc: 0.2188
[Telemetry][Blocks=1][Epoch 1][Iter 16] Train Loss: 2.8638 | Train Acc: 0.2812 | Val Loss: 2.6271 | Val Acc: 0.4062
[Telemetry][Blocks=1][Epoch 1][Iter 21] Train Loss: 2.5882 | Train Acc: 0.5312 | Val Loss: 2.4514 | Val Acc: 0.5312
[Telemetry][Blocks=1][Epoch 1][Iter 26] Train Loss: 2.1784 | Train Acc: 0.6250 | Val Loss: 2.0010 | Val Acc: 0.6562
[Telemetry][Blocks=1][Epoch 1][Iter 31] Train Loss: 1.9638 | Train Acc: 0.7500 | Val Loss: 1.7515 | Val Acc: 0.7812
[Telemetry][Blocks=1][Epoch 1][Iter 36] Train Loss: 1.9904 | Train Acc: 0.6875 | Val Loss: 1.5620 | Val Acc: 0.6562
[Telemetry][Blocks=1][Epoch 1][Iter 41] Train Loss: 1.8452 | Train Acc: 0.6250 | Val Loss: 1.6463 | Val Acc: 0.6875
[Telemetry][Blocks=1][Epoch 1][Iter 46] Train Loss: 1.7260 | Train Acc: 0.7188 | Val Loss: 1.4646 | Val Acc: 0.7188
[Telemetry][Blocks=1][Epoch 1][Iter 51] Train Loss: 1.4785 | Train Acc: 0.6562 | Val Loss: 1.1671 | Val Acc: 0.8750
[Telemetry][Blocks=1][Epoch 1][Iter 56] Train Loss: 1.3008 | Train Acc: 0.8438 | Val Loss: 1.1277 | Val Acc: 0.8125
[Telemetry][Blocks=1][Epoch 1][Iter 61] Train Loss: 1.3446 | Train Acc: 0.7500 | Val Loss: 1.0613 | Val Acc: 0.8125
[Telemetry][Blocks=1][Epoch 1][Iter 66] Train Loss: 1.1321 | Train Acc: 0.9062 | Val Loss: 0.9743 | Val Acc: 0.8750
[Telemetry][Blocks=1][Epoch 1][Iter 71] Train Loss: 1.2872 | Train Acc: 0.8125 | Val Loss: 0.8826 | Val Acc: 0.9375
[Telemetry][Blocks=1][Epoch 1][Iter 76] Train Loss: 0.9282 | Train Acc: 0.8438 | Val Loss: 1.0611 | Val Acc: 0.8438
[Telemetry][Blocks=1][Epoch 1][Iter 81] Train Loss: 0.8514 | Train Acc: 0.9062 | Val Loss: 0.8711 | Val Acc: 0.8438
[Telemetry][Blocks=1][Epoch 1][Iter 86] Train Loss: 0.8405 | Train Acc: 0.9375 | Val Loss: 0.9665 | Val Acc: 0.8125
[Telemetry][Blocks=1][Epoch 1][Iter 91] Train Loss: 0.9214 | Train Acc: 0.8125 | Val Loss: 0.7836 | Val Acc: 0.9062
[Telemetry][Blocks=1][Epoch 1][Iter 96] Train Loss: 0.7617 | Train Acc: 0.9062 | Val Loss: 0.9587 | Val Acc: 0.8750
[Telemetry][Blocks=1][Epoch 1] Batch 100/104 | Loss: 0.9988 | Acc: 0.9062
[Telemetry][Blocks=1][Epoch 1][Iter 101] Train Loss: 0.8585 | Train Acc: 0.8750 | Val Loss: 0.8989 | Val Acc: 0.8438
[Telemetry][Blocks=1][Epoch 1] Batch 104/104 | Loss: 0.8897 | Acc: 0.8750
[Telemetry][Blocks=1] Epoch 1 | Train Loss: 1.7385 | Train Acc: 0.6615 | Val Loss: 0.7224 | Val Acc: 0.8750
[Telemetry][Blocks=1] Final Validation Metrics | Loss: 0.7224 | Accuracy: 0.8750

[Telemetry] Training with 2 blocks unfrozen in layer4 + classifier
Total blocks in layer4: 3
Unfreezing layer4.block2
Unfreezing layer4.block1
Unfrozen blocks in layer4: [1, 2]

[Telemetry] Blocks=2, Starting epoch 1/1
[Telemetry][Blocks=2][Epoch 1][Iter 1] Train Loss: 3.6333 | Train Acc: 0.0000 | Val Loss: 3.7988 | Val Acc: 0.0625
[Telemetry][Blocks=2][Epoch 1][Iter 6] Train Loss: 3.0002 | Train Acc: 0.1875 | Val Loss: 3.2108 | Val Acc: 0.2500
[Telemetry][Blocks=2][Epoch 1][Iter 11] Train Loss: 2.7302 | Train Acc: 0.4062 | Val Loss: 2.9637 | Val Acc: 0.3125
[Telemetry][Blocks=2][Epoch 1][Iter 16] Train Loss: 2.4098 | Train Acc: 0.4375 | Val Loss: 1.7960 | Val Acc: 0.7500
[Telemetry][Blocks=2][Epoch 1][Iter 21] Train Loss: 2.0429 | Train Acc: 0.6562 | Val Loss: 1.8938 | Val Acc: 0.6875
[Telemetry][Blocks=2][Epoch 1][Iter 26] Train Loss: 2.0422 | Train Acc: 0.5625 | Val Loss: 1.6268 | Val Acc: 0.6250
[Telemetry][Blocks=2][Epoch 1][Iter 31] Train Loss: 1.7106 | Train Acc: 0.6875 | Val Loss: 1.2981 | Val Acc: 0.8125
[Telemetry][Blocks=2][Epoch 1][Iter 36] Train Loss: 1.4363 | Train Acc: 0.7812 | Val Loss: 1.2150 | Val Acc: 0.8125
[Telemetry][Blocks=2][Epoch 1][Iter 41] Train Loss: 1.2319 | Train Acc: 0.8750 | Val Loss: 1.0495 | Val Acc: 0.7188
[Telemetry][Blocks=2][Epoch 1][Iter 46] Train Loss: 0.9809 | Train Acc: 0.8750 | Val Loss: 0.9423 | Val Acc: 0.8750
[Telemetry][Blocks=2][Epoch 1][Iter 51] Train Loss: 0.9463 | Train Acc: 0.8750 | Val Loss: 0.8423 | Val Acc: 0.8438
[Telemetry][Blocks=2][Epoch 1][Iter 56] Train Loss: 1.0346 | Train Acc: 0.7188 | Val Loss: 0.7823 | Val Acc: 0.8438
[Telemetry][Blocks=2][Epoch 1][Iter 61] Train Loss: 0.9767 | Train Acc: 0.8438 | Val Loss: 0.8711 | Val Acc: 0.8750
[Telemetry][Blocks=2][Epoch 1][Iter 66] Train Loss: 1.0127 | Train Acc: 0.8125 | Val Loss: 0.9313 | Val Acc: 0.7812
[Telemetry][Blocks=2][Epoch 1][Iter 71] Train Loss: 0.7406 | Train Acc: 0.9062 | Val Loss: 0.7303 | Val Acc: 0.8750
[Telemetry][Blocks=2][Epoch 1][Iter 76] Train Loss: 0.9025 | Train Acc: 0.8125 | Val Loss: 0.8160 | Val Acc: 0.7500
[Telemetry][Blocks=2][Epoch 1][Iter 81] Train Loss: 0.7036 | Train Acc: 0.8750 | Val Loss: 0.5272 | Val Acc: 0.9062
[Telemetry][Blocks=2][Epoch 1][Iter 86] Train Loss: 0.7495 | Train Acc: 0.8438 | Val Loss: 0.4550 | Val Acc: 0.9375
[Telemetry][Blocks=2][Epoch 1][Iter 91] Train Loss: 0.7467 | Train Acc: 0.8750 | Val Loss: 0.4026 | Val Acc: 0.9688
[Telemetry][Blocks=2][Epoch 1][Iter 96] Train Loss: 0.6718 | Train Acc: 0.8750 | Val Loss: 0.3787 | Val Acc: 0.9688
[Telemetry][Blocks=2][Epoch 1] Batch 100/104 | Loss: 0.5194 | Acc: 0.9375
[Telemetry][Blocks=2][Epoch 1][Iter 101] Train Loss: 0.8041 | Train Acc: 0.7812 | Val Loss: 0.6201 | Val Acc: 0.8125
[Telemetry][Blocks=2][Epoch 1] Batch 104/104 | Loss: 1.0964 | Acc: 0.6875
[Telemetry][Blocks=2] Epoch 1 | Train Loss: 1.3927 | Train Acc: 0.7132 | Val Loss: 0.5373 | Val Acc: 0.8832
[Telemetry][Blocks=2] Final Validation Metrics | Loss: 0.5373 | Accuracy: 0.8832

[Telemetry] Training with 3 blocks unfrozen in layer4 + classifier
Total blocks in layer4: 3
Unfreezing layer4.block2
Unfreezing layer4.block1
Unfreezing layer4.block0
Unfrozen blocks in layer4: [0, 1, 2]

[Telemetry] Blocks=3, Starting epoch 1/1
[Telemetry][Blocks=3][Epoch 1][Iter 1] Train Loss: 3.6557 | Train Acc: 0.0312 | Val Loss: 3.5327 | Val Acc: 0.0938
[Telemetry][Blocks=3][Epoch 1][Iter 6] Train Loss: 3.0990 | Train Acc: 0.2500 | Val Loss: 3.1441 | Val Acc: 0.1562
[Telemetry][Blocks=3][Epoch 1][Iter 11] Train Loss: 2.9816 | Train Acc: 0.1250 | Val Loss: 2.3974 | Val Acc: 0.5312
[Telemetry][Blocks=3][Epoch 1][Iter 16] Train Loss: 2.3905 | Train Acc: 0.4062 | Val Loss: 1.8994 | Val Acc: 0.6250
[Telemetry][Blocks=3][Epoch 1][Iter 21] Train Loss: 2.0650 | Train Acc: 0.4688 | Val Loss: 1.5705 | Val Acc: 0.6875
[Telemetry][Blocks=3][Epoch 1][Iter 26] Train Loss: 1.5690 | Train Acc: 0.7812 | Val Loss: 1.2222 | Val Acc: 0.7500
[Telemetry][Blocks=3][Epoch 1][Iter 31] Train Loss: 1.3399 | Train Acc: 0.7188 | Val Loss: 1.1469 | Val Acc: 0.8125
[Telemetry][Blocks=3][Epoch 1][Iter 36] Train Loss: 1.3311 | Train Acc: 0.8125 | Val Loss: 0.8549 | Val Acc: 0.8750
[Telemetry][Blocks=3][Epoch 1][Iter 41] Train Loss: 1.0669 | Train Acc: 0.8750 | Val Loss: 0.8580 | Val Acc: 0.8750
[Telemetry][Blocks=3][Epoch 1][Iter 46] Train Loss: 1.1195 | Train Acc: 0.9062 | Val Loss: 1.0113 | Val Acc: 0.8125
[Telemetry][Blocks=3][Epoch 1][Iter 51] Train Loss: 0.7739 | Train Acc: 0.7812 | Val Loss: 0.9907 | Val Acc: 0.7812
[Telemetry][Blocks=3][Epoch 1][Iter 56] Train Loss: 0.8408 | Train Acc: 0.7812 | Val Loss: 0.8610 | Val Acc: 0.8750
[Telemetry][Blocks=3][Epoch 1][Iter 61] Train Loss: 1.1741 | Train Acc: 0.7812 | Val Loss: 0.5239 | Val Acc: 0.8750
[Telemetry][Blocks=3][Epoch 1][Iter 66] Train Loss: 0.8442 | Train Acc: 0.7500 | Val Loss: 0.5602 | Val Acc: 0.8750
[Telemetry][Blocks=3][Epoch 1][Iter 71] Train Loss: 0.8463 | Train Acc: 0.8438 | Val Loss: 0.8010 | Val Acc: 0.7812
[Telemetry][Blocks=3][Epoch 1][Iter 76] Train Loss: 0.5719 | Train Acc: 0.8750 | Val Loss: 0.5982 | Val Acc: 0.9062
[Telemetry][Blocks=3][Epoch 1][Iter 81] Train Loss: 0.4912 | Train Acc: 0.9062 | Val Loss: 0.4771 | Val Acc: 0.8750
[Telemetry][Blocks=3][Epoch 1][Iter 86] Train Loss: 0.5611 | Train Acc: 0.8750 | Val Loss: 0.3763 | Val Acc: 0.9062
[Telemetry][Blocks=3][Epoch 1][Iter 91] Train Loss: 0.6271 | Train Acc: 0.8750 | Val Loss: 0.5746 | Val Acc: 0.8438
[Telemetry][Blocks=3][Epoch 1][Iter 96] Train Loss: 0.6326 | Train Acc: 0.8438 | Val Loss: 0.4360 | Val Acc: 0.9062
[Telemetry][Blocks=3][Epoch 1] Batch 100/104 | Loss: 0.4802 | Acc: 0.9375
[Telemetry][Blocks=3][Epoch 1][Iter 101] Train Loss: 0.4931 | Train Acc: 0.7812 | Val Loss: 0.6200 | Val Acc: 0.7812
[Telemetry][Blocks=3][Epoch 1] Batch 104/104 | Loss: 0.4711 | Acc: 0.9375
[Telemetry][Blocks=3] Epoch 1 | Train Loss: 1.3067 | Train Acc: 0.7174 | Val Loss: 0.4793 | Val Acc: 0.8886
[Telemetry][Blocks=3] Final Validation Metrics | Loss: 0.4793 | Accuracy: 0.8886


## Stage 2 Multi-class Classification with Gradual Unfreezing (2025-05-15_23-09-05)
### Training Loss (Gradual Unfreezing)
![](./logs\plots\stage2-multiclass-2025-05-15_23-09-05-gradual-loss-train.png)

### Training Accuracy (Gradual Unfreezing)
![](./logs\plots\stage2-multiclass-2025-05-15_23-09-05-gradual-acc-train.png)

### Validation Loss (Gradual Unfreezing)
![](./logs\plots\stage2-multiclass-2025-05-15_23-09-05-gradual-loss-val.png)

### Validation Accuracy (Gradual Unfreezing)
![](./logs\plots\stage2-multiclass-2025-05-15_23-09-05-gradual-acc-val.png)

### Training vs Validation Loss (Gradual Unfreezing)
![](./logs\plots\stage2-multiclass-2025-05-15_23-09-05-gradual-train-vs-val-loss.png)

### Training vs Validation Accuracy (Gradual Unfreezing)
![](./logs\plots\stage2-multiclass-2025-05-15_23-09-05-gradual-train-vs-val-acc.png)


**Final Validation Metrics:**

- Loss: 0.5342
- Accuracy: 0.8587


**Training Log:**

[Telemetry] Number of training samples: 3312
[Telemetry] Number of validation samples: 368
[Telemetry] Batch size: 32
[Telemetry] Using device: cpu
[Telemetry] Strategy: simultaneous

[Telemetry] Starting training with gradual unfreezing

[Telemetry] Starting epoch 1/1
Progress: 1.0% - Unfrozen 1 blocks in layer4
[Epoch 1][Iter 1] Train Loss: 3.9952 | Train Acc: 0.0000 | Val Loss: 3.6809 | Val Acc: 0.0000
[Epoch 1][Iter 6] Train Loss: 3.5087 | Train Acc: 0.0625 | Val Loss: 3.5458 | Val Acc: 0.0625
[Epoch 1] Batch 10/104 | Blocks: 1 | Loss: 3.0756 | Acc: 0.2500
[Epoch 1][Iter 11] Train Loss: 3.2672 | Train Acc: 0.2188 | Val Loss: 3.1689 | Val Acc: 0.1875
[Epoch 1][Iter 16] Train Loss: 3.0829 | Train Acc: 0.2812 | Val Loss: 2.7691 | Val Acc: 0.3750
[Epoch 1] Batch 20/104 | Blocks: 1 | Loss: 2.4792 | Acc: 0.5625
[Epoch 1][Iter 21] Train Loss: 2.7400 | Train Acc: 0.3438 | Val Loss: 2.2911 | Val Acc: 0.4375
[Epoch 1][Iter 26] Train Loss: 2.3689 | Train Acc: 0.4688 | Val Loss: 2.1854 | Val Acc: 0.5625
[Epoch 1] Batch 30/104 | Blocks: 1 | Loss: 1.9343 | Acc: 0.7812
[Epoch 1][Iter 31] Train Loss: 2.0078 | Train Acc: 0.7188 | Val Loss: 1.9555 | Val Acc: 0.5938
Progress: 33.7% - Unfrozen 2 blocks in layer4
[Epoch 1][Iter 36] Train Loss: 1.8562 | Train Acc: 0.7188 | Val Loss: 1.5485 | Val Acc: 0.7188
[Epoch 1] Batch 40/104 | Blocks: 2 | Loss: 1.5208 | Acc: 0.7812
[Epoch 1][Iter 41] Train Loss: 1.7098 | Train Acc: 0.6250 | Val Loss: 1.2185 | Val Acc: 0.6875
[Epoch 1][Iter 46] Train Loss: 1.3430 | Train Acc: 0.7500 | Val Loss: 1.2871 | Val Acc: 0.6250
[Epoch 1] Batch 50/104 | Blocks: 2 | Loss: 1.2802 | Acc: 0.8125
[Epoch 1][Iter 51] Train Loss: 1.2771 | Train Acc: 0.7188 | Val Loss: 1.2288 | Val Acc: 0.6875
[Epoch 1][Iter 56] Train Loss: 1.1438 | Train Acc: 0.6875 | Val Loss: 1.0148 | Val Acc: 0.7500
[Epoch 1] Batch 60/104 | Blocks: 2 | Loss: 1.2216 | Acc: 0.6875
[Epoch 1][Iter 61] Train Loss: 1.5029 | Train Acc: 0.6250 | Val Loss: 1.0499 | Val Acc: 0.8125
[Epoch 1][Iter 66] Train Loss: 0.8878 | Train Acc: 0.8750 | Val Loss: 0.7612 | Val Acc: 0.8750
Progress: 67.3% - Unfrozen 3 blocks in layer4
[Epoch 1] Batch 70/104 | Blocks: 3 | Loss: 0.9474 | Acc: 0.8438
[Epoch 1][Iter 71] Train Loss: 0.7906 | Train Acc: 0.8438 | Val Loss: 0.8148 | Val Acc: 0.7812
[Epoch 1][Iter 76] Train Loss: 0.8256 | Train Acc: 0.9062 | Val Loss: 0.7972 | Val Acc: 0.8438
[Epoch 1] Batch 80/104 | Blocks: 3 | Loss: 1.1005 | Acc: 0.7188
[Epoch 1][Iter 81] Train Loss: 0.6564 | Train Acc: 0.9062 | Val Loss: 0.6355 | Val Acc: 0.8750
[Epoch 1][Iter 86] Train Loss: 0.6094 | Train Acc: 0.8438 | Val Loss: 0.5995 | Val Acc: 0.8438
[Epoch 1] Batch 90/104 | Blocks: 3 | Loss: 0.7683 | Acc: 0.7812
[Epoch 1][Iter 91] Train Loss: 0.7065 | Train Acc: 0.8750 | Val Loss: 0.3523 | Val Acc: 0.9688
[Epoch 1][Iter 96] Train Loss: 0.5678 | Train Acc: 0.8750 | Val Loss: 0.7525 | Val Acc: 0.8125
[Epoch 1] Batch 100/104 | Blocks: 3 | Loss: 0.6853 | Acc: 0.8125
[Epoch 1][Iter 101] Train Loss: 0.4132 | Train Acc: 0.9375 | Val Loss: 0.6719 | Val Acc: 0.7500
[Epoch 1] Batch 104/104 | Blocks: 3 | Loss: 0.7826 | Acc: 0.8750
[Telemetry] Epoch 1 | Train Loss: 1.6080 | Train Acc: 0.6639 | Val Loss: 0.5342 | Val Acc: 0.8587

[Telemetry] Final Model Validation | Loss: 0.5342 | Accuracy: 0.8587


## Stage 2 Multi-class Classification with Gradual Unfreezing (2025-05-15_23-19-09)
### Training vs Validation Loss per Iteration (Gradual Unfreezing)
![](./logs\plots\stage2-multiclass-2025-05-15_23-19-09-gradual-loss-combined.png)

### Training vs Validation Accuracy per Iteration (Gradual Unfreezing)
![](./logs\plots\stage2-multiclass-2025-05-15_23-19-09-gradual-acc-combined.png)

### Training vs Validation Loss per Epoch (Gradual Unfreezing)
![](./logs\plots\stage2-multiclass-2025-05-15_23-19-09-gradual-train-vs-val-loss.png)

### Training vs Validation Accuracy per Epoch (Gradual Unfreezing)
![](./logs\plots\stage2-multiclass-2025-05-15_23-19-09-gradual-train-vs-val-acc.png)


**Final Validation Metrics:**

- Loss: 0.5081
- Accuracy: 0.8886


**Training Log:**

[Telemetry] Number of training samples: 3312
[Telemetry] Number of validation samples: 368
[Telemetry] Batch size: 32
[Telemetry] Using device: cpu
[Telemetry] Strategy: simultaneous

[Telemetry] Starting training with gradual unfreezing

[Telemetry] Starting epoch 1/1
Progress: 1.0% - Unfrozen 1 blocks in layer4
[Epoch 1][Iter 1] Train Loss: 3.9982 | Train Acc: 0.0312 | Val Loss: 3.9760 | Val Acc: 0.0625
[Epoch 1][Iter 6] Train Loss: 3.4458 | Train Acc: 0.1875 | Val Loss: 3.2759 | Val Acc: 0.1562
[Epoch 1] Batch 10/104 | Blocks: 1 | Loss: 3.1946 | Acc: 0.2188
[Epoch 1][Iter 11] Train Loss: 3.2156 | Train Acc: 0.2812 | Val Loss: 2.9700 | Val Acc: 0.1875
[Epoch 1][Iter 16] Train Loss: 2.8142 | Train Acc: 0.3438 | Val Loss: 2.6114 | Val Acc: 0.4062
[Epoch 1] Batch 20/104 | Blocks: 1 | Loss: 2.7016 | Acc: 0.4062
[Epoch 1][Iter 21] Train Loss: 2.7339 | Train Acc: 0.3750 | Val Loss: 2.0933 | Val Acc: 0.6562
[Epoch 1][Iter 26] Train Loss: 2.0912 | Train Acc: 0.6562 | Val Loss: 1.9555 | Val Acc: 0.5938
[Epoch 1] Batch 30/104 | Blocks: 1 | Loss: 2.1637 | Acc: 0.5938
[Epoch 1][Iter 31] Train Loss: 2.0521 | Train Acc: 0.6562 | Val Loss: 1.8486 | Val Acc: 0.6250
Progress: 33.7% - Unfrozen 2 blocks in layer4
[Epoch 1][Iter 36] Train Loss: 2.0265 | Train Acc: 0.6250 | Val Loss: 1.6810 | Val Acc: 0.7188
[Epoch 1] Batch 40/104 | Blocks: 2 | Loss: 1.2890 | Acc: 0.9062
[Epoch 1][Iter 41] Train Loss: 1.7140 | Train Acc: 0.7500 | Val Loss: 1.4455 | Val Acc: 0.6562
[Epoch 1][Iter 46] Train Loss: 1.5945 | Train Acc: 0.6562 | Val Loss: 0.9872 | Val Acc: 0.8438
[Epoch 1] Batch 50/104 | Blocks: 2 | Loss: 1.2585 | Acc: 0.8125
[Epoch 1][Iter 51] Train Loss: 1.5372 | Train Acc: 0.6250 | Val Loss: 1.0806 | Val Acc: 0.8125
[Epoch 1][Iter 56] Train Loss: 1.1327 | Train Acc: 0.9062 | Val Loss: 0.7540 | Val Acc: 0.9062
[Epoch 1] Batch 60/104 | Blocks: 2 | Loss: 0.9916 | Acc: 0.8438
[Epoch 1][Iter 61] Train Loss: 1.0576 | Train Acc: 0.8438 | Val Loss: 0.7439 | Val Acc: 0.8438
[Epoch 1][Iter 66] Train Loss: 1.0276 | Train Acc: 0.8438 | Val Loss: 0.6793 | Val Acc: 0.9062
Progress: 67.3% - Unfrozen 3 blocks in layer4
[Epoch 1] Batch 70/104 | Blocks: 3 | Loss: 0.8767 | Acc: 0.8750
[Epoch 1][Iter 71] Train Loss: 0.9006 | Train Acc: 0.7812 | Val Loss: 0.6267 | Val Acc: 0.8125
[Epoch 1][Iter 76] Train Loss: 0.9464 | Train Acc: 0.8125 | Val Loss: 0.7572 | Val Acc: 0.8438
[Epoch 1] Batch 80/104 | Blocks: 3 | Loss: 0.9838 | Acc: 0.7500
[Epoch 1][Iter 81] Train Loss: 0.8873 | Train Acc: 0.7812 | Val Loss: 0.4961 | Val Acc: 0.8750
[Epoch 1][Iter 86] Train Loss: 0.7814 | Train Acc: 0.8438 | Val Loss: 0.7125 | Val Acc: 0.8125
[Epoch 1] Batch 90/104 | Blocks: 3 | Loss: 0.7993 | Acc: 0.8125
[Epoch 1][Iter 91] Train Loss: 0.6135 | Train Acc: 0.9688 | Val Loss: 0.5318 | Val Acc: 0.9375
[Epoch 1][Iter 96] Train Loss: 0.5774 | Train Acc: 0.9062 | Val Loss: 0.6367 | Val Acc: 0.8750
[Epoch 1] Batch 100/104 | Blocks: 3 | Loss: 0.6387 | Acc: 0.8438
[Epoch 1][Iter 101] Train Loss: 0.5699 | Train Acc: 0.9062 | Val Loss: 0.5064 | Val Acc: 0.9375
[Epoch 1] Batch 104/104 | Blocks: 3 | Loss: 0.5850 | Acc: 0.9375
[Telemetry] Epoch 1 | Train Loss: 1.6204 | Train Acc: 0.6688 | Val Loss: 0.5081 | Val Acc: 0.8886

[Telemetry] Final Model Validation | Loss: 0.5081 | Accuracy: 0.8886


## Stage 2 Multi-class Classification (2025-05-19_13-18-35)
### Training Configuration
- Strategy: simultaneous
- Data subset: 10.0%
- Epochs: 1
- Batch size: 32

### Final Metrics
- Training Loss: 3.2746
- Training Accuracy: 0.1511
- Validation Loss: 2.3961
- Validation Accuracy: 0.5676

### Training Log
[Telemetry] Number of training samples: 331
[Telemetry] Number of validation samples: 37
[Telemetry] Batch size: 32
[Telemetry] Using device: cpu
[Telemetry] Strategy: simultaneous
[Telemetry] Using 10.0% of data
Unfrozen blocks in layer4: [0, 1, 2]

[Telemetry] Starting training

[Telemetry] Starting epoch 1/1
Epoch 1 | Train Loss: 3.2746 | Train Acc: 0.1511

[Telemetry] Final Validation | Loss: 2.3961 | Accuracy: 0.5676


## Stage 2 Multi-class Classification (2025-05-19_13-25-13)
### Training Configuration
- Strategy: simultaneous
- Data subset: 100%
- Epochs: 1
- Batch size: 32

### Final Metrics
- Training Loss: 1.3013
- Training Accuracy: 0.7210
- Validation Loss: 0.4629
- Validation Accuracy: 0.8723

### Training Log
[Telemetry] Number of training samples: 3312
[Telemetry] Number of validation samples: 368
[Telemetry] Batch size: 32
[Telemetry] Using device: cpu
[Telemetry] Strategy: simultaneous
[Telemetry] Using 100% of data
Unfrozen blocks in layer4: [0, 1, 2]

[Telemetry] Starting training

[Telemetry] Starting epoch 1/1
Batch 50 | Val Loss: 0.8033 | Val Acc: 0.8424
Batch 100 | Val Loss: 0.4685 | Val Acc: 0.8777
Epoch 1 | Train Loss: 1.3013 | Train Acc: 0.7210

[Telemetry] Final Validation | Loss: 0.4629 | Accuracy: 0.8723


## Stage 2 Multi-class Classification with Gradual Unfreezing (2025-05-19_14-33-05)
### Training Configuration
- Strategy: simultaneous
- Batch norm unfreezing: True
- Epochs: 1
- Batch size: 32

### Training vs Validation Loss per Iteration
![](./logs\plots\stage2-multiclass-2025-05-19_14-33-05-gradual-loss-combined.png)

### Training vs Validation Accuracy per Iteration
![](./logs\plots\stage2-multiclass-2025-05-19_14-33-05-gradual-acc-combined.png)


**Final Validation Metrics:**

- Loss: 0.4781
- Accuracy: 0.8804


**Training Log:**

[Telemetry] Number of training samples: 3312
[Telemetry] Number of validation samples: 368
[Telemetry] Batch size: 32
[Telemetry] Using device: cpu
[Telemetry] Strategy: simultaneous
[Telemetry] Batch norm unfreezing: True
Batch normalization parameters unfrozen across all layers

[Telemetry] Starting training with gradual unfreezing

[Telemetry] Starting epoch 1/1
Progress: 1.0% - Unfrozen 1 blocks in layer4
[Epoch 1][Iter 1] Train Loss: 3.7856 | Train Acc: 0.0000 | Val Loss: 3.7976 | Val Acc: 0.0312
[Epoch 1][Iter 6] Train Loss: 3.4279 | Train Acc: 0.0938 | Val Loss: 3.3240 | Val Acc: 0.0625
[Epoch 1][Iter 11] Train Loss: 3.1282 | Train Acc: 0.1875 | Val Loss: 3.1113 | Val Acc: 0.1562
[Epoch 1][Iter 16] Train Loss: 2.7195 | Train Acc: 0.3750 | Val Loss: 2.7940 | Val Acc: 0.3125
[Epoch 1][Iter 21] Train Loss: 2.7388 | Train Acc: 0.2188 | Val Loss: 2.0859 | Val Acc: 0.6250
[Epoch 1][Iter 26] Train Loss: 2.1512 | Train Acc: 0.5000 | Val Loss: 2.0933 | Val Acc: 0.5000
[Epoch 1][Iter 31] Train Loss: 2.0295 | Train Acc: 0.5625 | Val Loss: 1.9851 | Val Acc: 0.6562
Progress: 33.7% - Unfrozen 2 blocks in layer4
[Epoch 1][Iter 36] Train Loss: 1.8988 | Train Acc: 0.7188 | Val Loss: 1.6090 | Val Acc: 0.5938
[Epoch 1][Iter 41] Train Loss: 1.5113 | Train Acc: 0.7812 | Val Loss: 1.7216 | Val Acc: 0.6250
[Epoch 1][Iter 46] Train Loss: 1.2498 | Train Acc: 0.8125 | Val Loss: 1.2429 | Val Acc: 0.6875
[Epoch 1][Iter 51] Train Loss: 1.2173 | Train Acc: 0.6562 | Val Loss: 1.0258 | Val Acc: 0.7812
[Epoch 1][Iter 56] Train Loss: 1.2205 | Train Acc: 0.7188 | Val Loss: 0.8439 | Val Acc: 0.8750
[Epoch 1][Iter 61] Train Loss: 0.9522 | Train Acc: 0.8750 | Val Loss: 0.6263 | Val Acc: 0.8750
[Epoch 1][Iter 66] Train Loss: 0.9893 | Train Acc: 0.8125 | Val Loss: 0.7004 | Val Acc: 0.9062
Progress: 67.3% - Unfrozen 3 blocks in layer4
[Epoch 1][Iter 71] Train Loss: 0.8844 | Train Acc: 0.8750 | Val Loss: 0.7412 | Val Acc: 0.7500
[Epoch 1][Iter 76] Train Loss: 0.9039 | Train Acc: 0.8125 | Val Loss: 0.6206 | Val Acc: 0.8438
[Epoch 1][Iter 81] Train Loss: 0.8621 | Train Acc: 0.8438 | Val Loss: 0.6971 | Val Acc: 0.8438
[Epoch 1][Iter 86] Train Loss: 0.7610 | Train Acc: 0.8125 | Val Loss: 0.6523 | Val Acc: 0.8750
[Epoch 1][Iter 91] Train Loss: 0.5392 | Train Acc: 0.8750 | Val Loss: 0.6554 | Val Acc: 0.9375
[Epoch 1][Iter 96] Train Loss: 0.6779 | Train Acc: 0.8750 | Val Loss: 0.5519 | Val Acc: 0.9062
[Epoch 1][Iter 101] Train Loss: 0.7005 | Train Acc: 0.8750 | Val Loss: 0.4561 | Val Acc: 0.9688
[Telemetry] Epoch 1 | Train Loss: 1.5766 | Train Acc: 0.6585 | Val Loss: 0.4781 | Val Acc: 0.8804

[Telemetry] Final Model Validation | Loss: 0.4781 | Accuracy: 0.8804


## Stage 2 Multi-class Classification with Data Augmentation and L2 Regularization (2025-05-19_16-37-42)

### Experiment: augmentation=none, L2 weight=0.0
Final Validation Loss: 0.5427
Final Validation Accuracy: 0.8940

Training vs Validation Loss:
![](./logs\plots\stage2-multiclass-2025-05-19_16-37-42-aug_none_l2_0.0-loss.png)

Training vs Validation Accuracy:
![](./logs\plots\stage2-multiclass-2025-05-19_16-37-42-aug_none_l2_0.0-acc.png)


### Experiment: augmentation=Less, L2 weight=0.0
Final Validation Loss: 0.6010
Final Validation Accuracy: 0.8451

Training vs Validation Loss:
![](./logs\plots\stage2-multiclass-2025-05-19_16-37-42-aug_Less_l2_0.0-loss.png)

Training vs Validation Accuracy:
![](./logs\plots\stage2-multiclass-2025-05-19_16-37-42-aug_Less_l2_0.0-acc.png)


### Experiment: augmentation=More, L2 weight=0.0
Final Validation Loss: 0.5813
Final Validation Accuracy: 0.8696

Training vs Validation Loss:
![](./logs\plots\stage2-multiclass-2025-05-19_16-37-42-aug_More_l2_0.0-loss.png)

Training vs Validation Accuracy:
![](./logs\plots\stage2-multiclass-2025-05-19_16-37-42-aug_More_l2_0.0-acc.png)


### Experiment: augmentation=Less, L2 weight=0.0001
Final Validation Loss: 0.5841
Final Validation Accuracy: 0.8560

Training vs Validation Loss:
![](./logs\plots\stage2-multiclass-2025-05-19_16-37-42-aug_Less_l2_0.0001-loss.png)

Training vs Validation Accuracy:
![](./logs\plots\stage2-multiclass-2025-05-19_16-37-42-aug_Less_l2_0.0001-acc.png)


### Experiment: augmentation=More, L2 weight=0.0001
Final Validation Loss: 0.5518
Final Validation Accuracy: 0.8696

Training vs Validation Loss:
![](./logs\plots\stage2-multiclass-2025-05-19_16-37-42-aug_More_l2_0.0001-loss.png)

Training vs Validation Accuracy:
![](./logs\plots\stage2-multiclass-2025-05-19_16-37-42-aug_More_l2_0.0001-acc.png)

